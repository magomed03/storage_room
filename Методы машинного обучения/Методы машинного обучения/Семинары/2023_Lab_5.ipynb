{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bbe095",
   "metadata": {
    "id": "a9bbe095"
   },
   "source": [
    "# Методы машинного обучения – Лабораторная работа №5\n",
    "\n",
    "# Рекуррентные нейронные сети RNN\n",
    "\n",
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27adad2",
   "metadata": {
    "id": "e27adad2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6eda2",
   "metadata": {
    "id": "a0a6eda2"
   },
   "source": [
    "## Задача аппроксимации синусоиды при помощи сети MLP\n",
    "\n",
    "В нейронных сетях прямого распространения (многослойных перцептронах, сетях MLP) поток данных движется только в одном направлении, а именно от входного слоя к выходному через скрытые слои."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc0dfc",
   "metadata": {
    "id": "3edc0dfc"
   },
   "source": [
    "Рассмотрим сеть прямого распространения (сеть MLP) с одним скрытым слоем, использующую нелинейную функцию активации, чтобы распознать нелинейную зависимость, задаваемую синусоидой. \n",
    "\n",
    "Будем использовать сеть MLP с одним входным нейроном, десятью скрытыми нейронами и одним выходным нейроном. Скрытые нейроны используют функцию активации гиперболический тангенс ($\\tanh$), тогда как выходной слой использует тождественную функцию активации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23686256",
   "metadata": {
    "id": "23686256"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_shape=(1,), activation='tanh', name='HiddenLayer'),  \n",
    "  tf.keras.layers.Dense(1, name='OutputLayer')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e343e90",
   "metadata": {
    "id": "7e343e90"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf4c09",
   "metadata": {
    "id": "2cbf4c09"
   },
   "source": [
    "При обучении нейронной сети будем использовать оптимизатор `rmsprop` (применяется по умолчанию). В качестве функции ошибок (потерь) будем использовать среднеквадратичную ошибку MSE (mean squared error), а для оценки качества модели – среднюю абсолютную ошибку MAE (mean absolute error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e5dafb",
   "metadata": {
    "id": "a9e5dafb"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", # по умолчанию\n",
    "              loss=\"mse\",\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0118d39",
   "metadata": {
    "id": "d0118d39"
   },
   "source": [
    "Обучающие данные содержат $50$ точек $x_{i}$, выбранных случайным образом в диапазоне $\\left[-10,\\,10\\right]$, где $y_{i}=\\sin\\left(x_{i}\\right)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38756f5",
   "metadata": {
    "id": "d38756f5"
   },
   "outputs": [],
   "source": [
    "x_train = 20 * np.random.random(50) - 10\n",
    "y_train = np.sin(x_train)\n",
    "\n",
    "x_plot = np.linspace(-10,10,101)\n",
    "y_plot = np.sin(x_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9bcbf",
   "metadata": {
    "id": "56c9bcbf"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "plt.plot(x_plot, y_plot, c='b')\n",
    "plt.scatter(x_train, y_train, s=100, c='r', marker='*');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4374dd1b",
   "metadata": {
    "id": "4374dd1b"
   },
   "source": [
    "Будем обучать нейронную сеть на сгенерированных 50 точках, увеличивая количество эпох обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e29d182",
   "metadata": {
    "id": "5e29d182"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, verbose=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e24f8e",
   "metadata": {
    "id": "38e24f8e"
   },
   "source": [
    "Оценим качество полученной модели на множестве равноотстоящих точек из отрезка $[-10,10]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd14878",
   "metadata": {
    "id": "bdd14878"
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(-10,10,1001)\n",
    "y_pred = model.predict(x_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1553b68",
   "metadata": {
    "id": "e1553b68"
   },
   "source": [
    "Для визуализации прогноза модели будем использовать функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c78e4",
   "metadata": {
    "id": "7d3c78e4"
   },
   "outputs": [],
   "source": [
    "def show_sin():\n",
    "    print('MSE: {:.3f}, MAE:{:.3f}'.format(*model.evaluate(x_plot, y_plot, verbose=0)))\n",
    "\n",
    "    plt.plot(x_plot, y_plot, c='b')\n",
    "    plt.scatter(x_train, y_train, s=100, c='r', marker='*')\n",
    "    plt.plot(x_pred, y_pred, c='g', lw=3, alpha=0.5);\n",
    "    \n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b6f508",
   "metadata": {
    "id": "79b6f508"
   },
   "source": [
    "Увеличим количество эпох обучения до десяти тысяч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619dcbc",
   "metadata": {
    "id": "f619dcbc"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, initial_epoch=1000, epochs=10000, verbose=0);\n",
    "y_pred = model.predict(x_pred)\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c151cc8",
   "metadata": {
    "id": "3c151cc8"
   },
   "source": [
    "До двацати тысяч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c19113",
   "metadata": {
    "id": "80c19113"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, initial_epoch=10000, epochs=20000, verbose=0);\n",
    "y_pred = model.predict(x_pred)\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba2e65",
   "metadata": {
    "id": "82ba2e65"
   },
   "source": [
    "И, наконец, до тридцати тысяч:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec5307",
   "metadata": {
    "id": "a6ec5307"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, initial_epoch=20000, epochs=30000, verbose=0);\n",
    "y_pred = model.predict(x_pred)\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0a60b",
   "metadata": {
    "id": "85b0a60b"
   },
   "source": [
    "Рисунок свидетельствует о хорошем качестве аппроксимации синусоиды нейронной сетью.\n",
    "\n",
    "Однако выполним прогноз для значений из расширенного диапазона $[-20,20]$ и нарисуем кривые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b33be8",
   "metadata": {
    "id": "d6b33be8"
   },
   "outputs": [],
   "source": [
    "x_pred = np.linspace(-20,20,1001)\n",
    "y_pred = model.predict(x_pred)\n",
    "\n",
    "show_sin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc682bcf",
   "metadata": {
    "id": "fc682bcf"
   },
   "source": [
    "Таким образом, фактически нейронная сеть прямого распространения только аппроксимировала синусоиду на интервале $[-10,10]$ и не выявила периодичность аппроксимируемой функции. \n",
    "\n",
    "## Задача прогнозирования поведения синусоиды при помощи сети MLP\n",
    "\n",
    "Рассмотрим теперь задачу прогнозирования значений синусоиды.\n",
    "\n",
    "Будем рассматривать в качестве исходного датасета набор значений синусоиды на интервале от $[-10,10]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053e4d3",
   "metadata": {
    "id": "d053e4d3"
   },
   "outputs": [],
   "source": [
    "ds_data = np.sin(np.linspace(-10,10,1001))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "niNRxIVx_CCt",
   "metadata": {
    "id": "niNRxIVx_CCt"
   },
   "source": [
    "Обучающая выборка составляет 80% всех данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550dcf5",
   "metadata": {
    "id": "3550dcf5"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(ds_data) * 0.8)\n",
    "test_size = len(ds_data) - train_size\n",
    "ds_train, ds_test = ds_data[:train_size], ds_data[train_size:]\n",
    "ds_train.shape, ds_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iRV2S2Cc_Mdp",
   "metadata": {
    "id": "iRV2S2Cc_Mdp"
   },
   "source": [
    "Конвертируем исходный набор в нужный формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c663775",
   "metadata": {
    "id": "5c663775"
   },
   "outputs": [],
   "source": [
    "def create_ds(ds, look_back=1):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(ds)-look_back-1):\n",
    "    a = ds[i:(i+look_back)]\n",
    "    dataX.append(a)\n",
    "    dataY.append(ds[i + look_back])\n",
    "  return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-hgdEdiy_ZhJ",
   "metadata": {
    "id": "-hgdEdiy_ZhJ"
   },
   "source": [
    "Будем делать прогноз на основе 10 предыдущих значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c5d33",
   "metadata": {
    "id": "432c5d33"
   },
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_ds(ds_train, look_back=look_back)\n",
    "testX, testY = create_ds(ds_test, look_back=look_back)\n",
    "trainX.shape, trainY.shape, testX.shape, testY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MRj8k9Lo_jGo",
   "metadata": {
    "id": "MRj8k9Lo_jGo"
   },
   "source": [
    "Изменим форму обучающего и тестового наборов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e58d60",
   "metadata": {
    "id": "02e58d60"
   },
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "trainX.shape, testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LTU3F0pA_tG8",
   "metadata": {
    "id": "LTU3F0pA_tG8"
   },
   "source": [
    "Создадим сеть MLP с одним скрытым слоем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a647dc",
   "metadata": {
    "id": "09a647dc"
   },
   "outputs": [],
   "source": [
    "model_mlp = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, input_shape=(1,look_back), activation='tanh', name='HiddenLayer'),  \n",
    "  tf.keras.layers.Dense(1, name='OutputLayer')])\n",
    "model_mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de0567",
   "metadata": {
    "id": "f9de0567"
   },
   "outputs": [],
   "source": [
    "model_mlp.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_mlp.fit(trainX, trainY, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsXSd9OK_2cj",
   "metadata": {
    "id": "VsXSd9OK_2cj"
   },
   "source": [
    "Выполним прогноз:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fab275",
   "metadata": {
    "id": "a7fab275"
   },
   "outputs": [],
   "source": [
    "trainPredict = model_mlp.predict(trainX)\n",
    "testPredict = model_mlp.predict(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CuVJzyyc_5eb",
   "metadata": {
    "id": "CuVJzyyc_5eb"
   },
   "source": [
    "Используем для оценки качества показатель RMSE, вычисляемый через MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R9VhhVGyCNMl",
   "metadata": {
    "id": "R9VhhVGyCNMl"
   },
   "outputs": [],
   "source": [
    "def my_mse(y_test, y_predict):\n",
    "    return np.sum((y_predict - y_test)**2) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e8c75",
   "metadata": {
    "id": "ac7e8c75"
   },
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(my_mse(trainY, trainPredict.reshape(-1)))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(my_mse(testY, testPredict.reshape(-1)))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsHq2W6tAIiW",
   "metadata": {
    "id": "VsHq2W6tAIiW"
   },
   "source": [
    "Для корректной визуализации данных нужно сдвинуть данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c12386",
   "metadata": {
    "id": "a9c12386"
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(ds_data)\n",
    "trainPredictPlot[:] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict) + look_back] = trainPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dd356",
   "metadata": {
    "id": "261dd356"
   },
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(ds_data)\n",
    "testPredictPlot[:,] = np.nan\n",
    "testPredictPlot[len(trainPredict) + (look_back * 2) + 1:len(ds_data) - 1] = testPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259461c4",
   "metadata": {
    "id": "259461c4"
   },
   "outputs": [],
   "source": [
    "plt.plot(ds_data, label='Actual')\n",
    "plt.plot(trainPredictPlot.reshape(-1), label='Training')\n",
    "plt.plot(testPredictPlot.reshape(-1), label='Testing')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d0bcf",
   "metadata": {
    "id": "ee5d0bcf"
   },
   "source": [
    "### Решение проблемы исчезающих градиентов\n",
    "\n",
    "#### Инициализация весов\n",
    "\n",
    "Для управления инициализацией весов нужно указать при создании слоя параметр `kernel_initializer`, например, так:\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation = \"relu\", kernel_initializer=\"he_normal\")`\n",
    "\n",
    "или\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation = \"relu\", kernel_initializer=\"he_uniform\")`\n",
    "\n",
    "или\n",
    "\n",
    "`tf.keras.layers.Dense(10, activation = \"sigmoid\", kernel_initializer=keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xy4Xw1alFImF",
   "metadata": {
    "id": "xy4Xw1alFImF"
   },
   "source": [
    "#### Использование функций активации без насыщения\n",
    "\n",
    "Например, можно использовать функцию активации `SELU` (Scaled Exponential Linear Unit) с инициализацией весов `lecun_normal` так:\n",
    "\n",
    "`model.add(tf.keras.layers.Dense(10, kernel_initializer='lecun_normal',\n",
    "                                 activation='selu'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ekV45kg8FLiV",
   "metadata": {
    "id": "ekV45kg8FLiV"
   },
   "source": [
    "#### Пакетная нормализация (Batch Normalization)\n",
    "\n",
    "Слой пакетной нормализации может быть добавлен в модель так:\n",
    "\n",
    "`model.add(tf.keras.layers.BatchNormalization())`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-jiugeceFXXT",
   "metadata": {
    "id": "-jiugeceFXXT"
   },
   "source": [
    "#### Обрезка градиентов (Gradient Clipping)\n",
    "\n",
    "При обрезке градентов при задании оптимизатора в методе `compile()` указывается параметр `clipvalue` или `clipnorm`, например: \n",
    "\n",
    "`model.compile(optimizer=optimizer = keras.optimizers.SGD(clipvalue = 1.0),\n",
    "              loss=\"mse\", metrics=[\"mae\"])`   \n",
    "\n",
    "или\n",
    "\n",
    "`model.compile(optimizer=optimizer = keras.optimizers.SGD(clipnorm = 1.0),\n",
    "              loss=\"mse\", metrics=[\"mae\"])` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzMlqRQ8AWe1",
   "metadata": {
    "id": "wzMlqRQ8AWe1"
   },
   "source": [
    "Попробуем решить задачу прогноза значений синусоиды при помощи глубокой сети MLP с применением пакетной нормализации, функций активации без насыщения и альтернативной инициализации весов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb7acc6",
   "metadata": {
    "id": "9cb7acc6"
   },
   "outputs": [],
   "source": [
    "model_dmlp = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(1,look_back), \n",
    "                          kernel_initializer='lecun_normal', activation='selu'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, kernel_initializer='lecun_normal', activation='selu'),  \n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(1, name='OutputLayer')])\n",
    "model_dmlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a3fd7",
   "metadata": {
    "id": "001a3fd7"
   },
   "outputs": [],
   "source": [
    "model_dmlp.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_dmlp.fit(trainX, trainY, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7JMB4NJHF3Xe",
   "metadata": {
    "id": "7JMB4NJHF3Xe"
   },
   "outputs": [],
   "source": [
    "trainPredict = model_dmlp.predict(trainX)\n",
    "testPredict = model_dmlp.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZJKwaWSJF_qj",
   "metadata": {
    "id": "ZJKwaWSJF_qj"
   },
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(my_mse(trainY, trainPredict.reshape(-1)))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(my_mse(testY, testPredict.reshape(-1)))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joiDaqT6GVm8",
   "metadata": {
    "id": "joiDaqT6GVm8"
   },
   "source": [
    "## Рекуррентная нейронная сеть RNN\n",
    "\n",
    "__Рекуррентные нейронные сети__ (Recurrent Neural Networks, __RNN__) включают обратную связь от одного уровня к другому, и их обычно можно обучить, развертывая рекуррентные соединения, в результате чего получаются глубокие сети, параметры которых можно обучить с помощью алгоритма обратного распространения ошибки. \n",
    "\n",
    "Если многослойные персептроны представляют собой сети прямого распространения, в которых информация движется только в одном направлении, а именно от входного слоя к выходному через скрытые слои, то рекуррентные нейронные сети (RNN) содержат петли (циклы) обратной связи между двумя (или более) слоями, что делает их идеальными для обучения на основе входных данных в форме последовательностей. \n",
    "\n",
    "Задача сети RNN состоит в том, чтобы аппроксимировать функцию, которая предсказывает целевую выходную последовательность $\\mathcal{Y}$ по заданной входной последовательности $\\mathcal{X}$. То есть прогнозируемые выходные данные (результат) $\\mathbf{o}_{t}$ для входных данных $\\mathbf{x}_{t}$ должны быть аналогичны или близки к целевому отклику $\\mathbf{y}_{t}$ для каждого момента времени $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabfac4",
   "metadata": {
    "id": "4dabfac4"
   },
   "outputs": [],
   "source": [
    "model_rnn = tf.keras.Sequential([\n",
    "  tf.keras.layers.SimpleRNN(10, input_shape=(1,look_back), name='HiddenLayer'),  \n",
    "  tf.keras.layers.Dense(1, name='OutputLayer')])\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea77e3",
   "metadata": {
    "id": "08ea77e3"
   },
   "outputs": [],
   "source": [
    "model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_rnn.fit(trainX, trainY, epochs=100, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304173bb",
   "metadata": {
    "id": "304173bb"
   },
   "outputs": [],
   "source": [
    "trainPredict = model_rnn.predict(trainX)\n",
    "testPredict = model_rnn.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031b094",
   "metadata": {
    "id": "7031b094"
   },
   "outputs": [],
   "source": [
    "trainScore = np.sqrt(my_mse(trainY, trainPredict.reshape(-1)))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(my_mse(testY, testPredict.reshape(-1)))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef76cad7",
   "metadata": {
    "id": "ef76cad7"
   },
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(ds_data)\n",
    "trainPredictPlot[:] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict) + look_back] = trainPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5738ecd3",
   "metadata": {
    "id": "5738ecd3"
   },
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(ds_data)\n",
    "testPredictPlot[:,] = np.nan\n",
    "testPredictPlot[len(trainPredict) + (look_back * 2) + 1:len(ds_data) - 1] = testPredict.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8f7ef",
   "metadata": {
    "id": "57d8f7ef"
   },
   "outputs": [],
   "source": [
    "plt.plot(ds_data, marker='o', c='y', lw=5, label='Actual')\n",
    "plt.plot(trainPredictPlot.reshape(-1), c='b', label='Training')\n",
    "plt.plot(testPredictPlot.reshape(-1), c='r', label='Testing')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f131a45",
   "metadata": {
    "id": "8f131a45"
   },
   "source": [
    "Рассмотрим теперь более общую задачу прогнозирования значений временного ряда."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb3a1e",
   "metadata": {
    "id": "62eb3a1e"
   },
   "source": [
    "## Прогнозирование значений временного ряда\n",
    "\n",
    "_Временной ряд_ представляет собой любые данные, полученные путем измерений через равные промежутки времени, например, дневная цена акции, почасовое потребление электроэнергии в городе или еженедельные продажи в магазине. Временные ряды встречаются в различных сферах  деятельности от изучения природных явлений (сейсмическую активность, эволюция популяций рыб в реке, погода в определенном месте и пр.) до экономики (посетители веб-сайта, ВВП страны, операции с кредитными картами и т.п.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce266e",
   "metadata": {
    "id": "51ce266e"
   },
   "source": [
    "Наиболее распространенной задачей, связанной с временными рядами, является прогнозирование – предсказание дальнейшей динамики временного ряда. Необходимо прогнозировать потребление электроэнергии, чтобы предвидеть спрос; прогнозировать доход на несколько месяцев вперед, чтобы планировать бюджет; прогнозировать погоду на несколько дней вперед, чтобы планировать расписание."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97916d",
   "metadata": {
    "id": "5a97916d"
   },
   "source": [
    "Рассмотрим задачу прогнозирования температуры воздуха через 24 часа, учитывая временной ряд часовых измерений таких величин, как атмосферное давление и влажность. \n",
    "\n",
    "Этот набор данных был записан на метеостанции в Институте биогеохимии им. Макса Планка в Йене, Германия. В этом наборе 14 различных величин (таких как температура, давление, влажность, направление ветра и т.д.) записанных с интервалом 10 минут за несколько лет. Набор можно загрузить по адресу `https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df800987",
   "metadata": {
    "id": "df800987"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "fname = os.path.join(\"jena_climate_2009_2016.csv\")\n",
    "\n",
    "with open(fname) as f:\n",
    "    data = f.read()\n",
    "\n",
    "lines = data.split(\"\\n\")      # list with headers and text lines with date and data\n",
    "header = lines[0].split(\",\")  # list of column names\n",
    "lines = lines[1:]             # list of text lines with date and data\n",
    "print('Атрибуты набора данных:', header)\n",
    "print('\\nКоличество записей:', len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d28e4",
   "metadata": {
    "id": "ff1d28e4"
   },
   "source": [
    "Всего в наборе 420451 строк данных (записей), содержащих метку с датой/временем и 14 погодных показателей. Исключим столбец с датой/временем и загрузим температурные показатели в массив `temperature` и все показатели (включая температуру) в массив `raw_data`. \n",
    "\n",
    "Нарисуем также график температуры (в градусах Цельсия) в зависимости от времени (номера записи):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c9aefa",
   "metadata": {
    "id": "56c9aefa"
   },
   "outputs": [],
   "source": [
    "temperature = np.zeros((len(lines),))\n",
    "raw_data = np.zeros((len(lines), len(header) - 1))\n",
    "for i, line in enumerate(lines):\n",
    "    values = [float(x) for x in line.split(\",\")[1:]] # list of values w/o date\n",
    "    temperature[i] = values[1]                       # temperature only\n",
    "    raw_data[i, :] = values[:]                       # all values\n",
    "    \n",
    "plt.plot(range(len(temperature)), temperature);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76407663",
   "metadata": {
    "id": "76407663"
   },
   "source": [
    "На графике прослеживаются сезонные изменения температуры (за 8 лет). Однако температура также изменяется в зависимости от времени суток. Это видно на температурном графике за 10 дней (т.к. данные измеряются каждые 10 минут, ежедневно сохраняется $24 * 6 = 144$ записи)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf1dc9",
   "metadata": {
    "id": "8adf1dc9"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1440), temperature[:1440]); # 1440 = 10 x 24 x 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8bc40",
   "metadata": {
    "id": "87c8bc40"
   },
   "source": [
    "Будем использовать первые 50% данных в наборе для обучения, следующие 25% для валидации и последние 25% для тестирования. Вычислим количество записей в обучающей, валидационной и тестовой выборках: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7574838",
   "metadata": {
    "id": "e7574838"
   },
   "outputs": [],
   "source": [
    "num_train_samples = int(0.5 * len(raw_data))\n",
    "num_val_samples = int(0.25 * len(raw_data))\n",
    "num_test_samples = len(raw_data) - num_train_samples - num_val_samples\n",
    "print(\"num_train_samples:\", num_train_samples)\n",
    "print(\"num_val_samples:\", num_val_samples)\n",
    "print(\"num_test_samples:\", num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09ea11",
   "metadata": {
    "id": "5c09ea11"
   },
   "source": [
    "Нормализуем каждый столбец в массиве `raw_data` по данным обучающей выборки (по первым `num_train_samples` записям), чтобы все столбцы принимали небольшие значения в одинаковом масштабе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8b1c2",
   "metadata": {
    "id": "51a8b1c2"
   },
   "outputs": [],
   "source": [
    "mean = raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data -= mean\n",
    "std = raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data /= std # whole raw_data normalized w.r.t. first num_train_samples rows\n",
    "\n",
    "mean.shape, std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf425602",
   "metadata": {
    "id": "cf425602"
   },
   "source": [
    "Теперь создадим набор (объект) с данными за последние пять дней вместе с целевым показателем температуры через 24 часа. Для этого используем встроенную в модуль Keras функцию `timeseries_dataset_from_array()`. Чтобы проиллюстрировать работу этой функции, рассмотрим следующий простой пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb8be34",
   "metadata": {
    "id": "0eb8be34"
   },
   "outputs": [],
   "source": [
    "int_sequence = np.arange(10)   # [0,1,2,3,4,5,6,7,8,9]\n",
    "dummy_dataset = tf.keras.utils.timeseries_dataset_from_array( # объект BatchDataset\n",
    "    data=int_sequence[:-3],    # [0,1,2,3,4,5,6]\n",
    "    targets=int_sequence[3:],  # [3,4,5,6,7,8,9]\n",
    "    sequence_length=3,         # длина последовательности\n",
    "    batch_size=2,              # размер батча (пакета)\n",
    ")\n",
    "\n",
    "for inputs, targets in dummy_dataset: # tf.Tensor objects\n",
    "    for i in range(inputs.shape[0]):\n",
    "        print([int(x) for x in inputs[i]], int(targets[i]))\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25fc44",
   "metadata": {
    "id": "4a25fc44"
   },
   "source": [
    "Используем `timeseries_dataset_from_array()` для создания трех наборов данных (объектов `BatchDataset`) – для обучения, для валидации и для тестирования со следующими значениями параметров:\n",
    "\n",
    "* `sample_rate = 6` — наблюдения будут производиться в одной точке данных в час - будем хранить только одну точку данных из 6;\n",
    "* `sequence_length=120` — наблюдения будут браться за 5 дней (120 часов);\n",
    "* `delay=sampling_rate*(sequence_length+24-1)` — целью для входной последовательности будет температура через 24 часа после окончания последовательности;\n",
    "\n",
    "При создании набора обучающих данных передадим в функцию аргементы `start_index = 0` и `end_index = num_train_samples`, чтобы использовать только первые 50% данных. Для набора данных валидации передадим в функцию `start_index = num_train_samples` и `end_index = num_train_samples + num_val_samples`, чтобы использовать следующие 25% данных. Наконец, для тестового набора данных передадим `start_index=num_train_samples+num_val_samples`, чтобы использовать оставшиеся данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1001f07",
   "metadata": {
    "id": "d1001f07"
   },
   "outputs": [],
   "source": [
    "sampling_rate = 6\n",
    "sequence_length = 120\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples)\n",
    "\n",
    "val_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "test_dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f4359",
   "metadata": {
    "id": "299f4359"
   },
   "source": [
    "Каждый набор данных содержит кортежи `(samples, targets)`, где `samples` представляет собой пакет из 256 записей, каждая из которых содержит 120 последовательных часовых записей данных, а `targets` представляет собой соответствующий массив из 256 температур. Обратите внимание, что записи перемешиваются случайным образом, поэтому две соседние последовательности в пакете (например, `samples[0]` и `samples[1]`) не обязательно близки по времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b33ac",
   "metadata": {
    "id": "483b33ac"
   },
   "outputs": [],
   "source": [
    "for samples, targets in train_dataset: # shapes in first data batch\n",
    "    print(\"Форма признаков:\", samples.shape)\n",
    "    print(\"Форма откликов:\", targets.shape)\n",
    "    break # first batch only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a4656",
   "metadata": {
    "id": "803a4656"
   },
   "source": [
    "Оценим ошибку для следующего элементарного подхода к прогнозированию температуры, когда в качестве прогнозного значения температуры через 24 часа принимается текущее значение температуры. В качестве показателя качества модели прогнозирования будем использовать метрику MAE (mean absolute error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a46fc7",
   "metadata": {
    "id": "58a46fc7"
   },
   "outputs": [],
   "source": [
    "def evaluate_naive_method(dataset):\n",
    "    total_abs_err = 0.\n",
    "    samples_seen = 0\n",
    "    for samples, targets in dataset:\n",
    "        preds = samples[:, -1, 1] * std[1] + mean[1] # std and mean of temperature\n",
    "        total_abs_err += np.sum(np.abs(preds - targets))\n",
    "        samples_seen += samples.shape[0]\n",
    "    return total_abs_err / samples_seen\n",
    "\n",
    "print(f\"MAE на валидационном наборе: {evaluate_naive_method(val_dataset):.2f}\")\n",
    "print(f\"MAE на тестовом наборе: {evaluate_naive_method(test_dataset):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2269a7",
   "metadata": {
    "id": "8e2269a7"
   },
   "source": [
    "## Прогнозирование температуры при помощи сети MLP\n",
    "\n",
    "Рассмотрим модель нейронной сети прямого распространения (сети MLP), которая начинается с выравнивания данных, а затем проходит через два плотных слоя. Функция активации на последнем плотном слое (выходном слое)  отсутствует, что типично для задачи регрессии. В качестве потерь используется среднеквадратичную ошибку (MSE), так как, в отличие от MAE, функция MSE гладкая около нуля, что является полезным свойством для градиентного спуска. Показатель MAE будет отслеживаться в качестве метрики модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443668",
   "metadata": {
    "id": "f6443668"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(16, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=5,\n",
    "                    validation_data=val_dataset,\n",
    "                   ) \n",
    "\n",
    "print(f\"MAE на тестовом наборе: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uGzV7zqGurh6",
   "metadata": {
    "id": "uGzV7zqGurh6"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c42c5",
   "metadata": {
    "id": "f63c42c5"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"MAE на обучающей выборке\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"MAE на валидационной выборке\")\n",
    "plt.title(\"Ошибка MAE на обучающей и валидационной выборках\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd29158",
   "metadata": {
    "id": "2fd29158"
   },
   "source": [
    "Результаты обучение нейронной сети свидетельствуют, что ошибка построенной модели на валидационном наборе (а также на тестовом наборе) превышает аналогичные ошибки для наивной модели прогнозирования температуры. Поэтому использование нейронной сети прямого распространения не позволяет получить модель прогнозирования приемлемого качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60e6c4",
   "metadata": {
    "id": "bb60e6c4"
   },
   "source": [
    "## Прогнозирование температуры при помощи сети RNN\n",
    "\n",
    "Попробуем теперь построить модель прогнозирования температуры на основе простой сети RNN с одним скрытым слоем c 16 нейронами и выходным слоем из одного нейрона:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7c73e",
   "metadata": {
    "id": "55f7c73e"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = tf.keras.layers.LSTM(16)(inputs) \n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=5,\n",
    "                    validation_data=val_dataset,\n",
    "                   ) \n",
    "\n",
    "print(f\"Test MAE: {model.evaluate(test_dataset)[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422a917",
   "metadata": {
    "id": "9422a917"
   },
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs[1:], loss[1:], \"bo\", label=\"MAE на обучающей выборке\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"MAE на валидационной выборке\")\n",
    "plt.title(\"Ошибка MAE на обучающей и валидационной выборках\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d353da14",
   "metadata": {
    "id": "d353da14"
   },
   "source": [
    "Таким образом, применение сети RNN позволило улучшить показатели качества модели прогнозирования и получить модель с лучшим качеством прогноза, чем наивная модель прогнозирования. \n",
    "\n",
    "Почему получилось улучшить показатели качества модели по сравнению с моделью на основе сети MLP? Сети прямого распространения (сети MLP) не имеют памяти. Каждый элемент входных данных обрабатывается независимо, при этом, чтобы обработать последовательность или временной ряд точек данных, нужно отправить всю последовательность данных нейронной сети сразу, превратив ее в единую точку данных. \n",
    "\n",
    "Рекуррентная нейронная сеть (RNN) обрабатывает последовательность данных, перебирая элементы последовательности и поддерживая внутреннее состояние, содержащее информацию относительно того, что сеть видела до сих пор. По сути, сеть RNN — это тип нейронной сети с внутренним циклом.\n",
    "\n",
    "Состояние сети RNN сбрасывается между обработкой двух разных независимых последовательностей (например, двух записей в пакете), так что по-прежнему  последовательность считается одной точкой данных. Но эта точка данных больше не обрабатывается за один шаг – скорее, сеть внутренне зацикливается на элементах последовательности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e212eLUJ3VWz",
   "metadata": {
    "id": "e212eLUJ3VWz"
   },
   "source": [
    "## Загрузка котировок акций из Yahoo Finance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ARo_KPm-yPL",
   "metadata": {
    "id": "7ARo_KPm-yPL"
   },
   "outputs": [],
   "source": [
    "#!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ff2a0",
   "metadata": {
    "id": "294ff2a0"
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yfin\n",
    "import datetime as dt\n",
    "\n",
    "yfin.pdr_override()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fNnuJCo2BNQf",
   "metadata": {
    "id": "fNnuJCo2BNQf"
   },
   "source": [
    "Загрузим ежедневные котировки акций компании Apple за период с 1 января 2016 по май 2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KYsxeDNn3bQJ",
   "metadata": {
    "id": "KYsxeDNn3bQJ"
   },
   "outputs": [],
   "source": [
    "aapl = pdr.get_data_yahoo('AAPL', \n",
    "                          start=dt.datetime(2016, 1, 1), \n",
    "                          end=dt.datetime(2022, 5, 31))\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iTdmAMxqKKD-",
   "metadata": {
    "id": "iTdmAMxqKKD-"
   },
   "outputs": [],
   "source": [
    "aapl.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZUKlWujeImXG",
   "metadata": {
    "id": "ZUKlWujeImXG"
   },
   "source": [
    "Извлечем первые записи с котировками за май 2022 г.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kq0wvDaK3hIv",
   "metadata": {
    "id": "kq0wvDaK3hIv"
   },
   "outputs": [],
   "source": [
    "aapl.loc[pd.Timestamp('2022-05-01'):pd.Timestamp('2022-05-31')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aE0Q__IhI0ZA",
   "metadata": {
    "id": "aE0Q__IhI0ZA"
   },
   "source": [
    "Извлечем первые записи с котировками за 2022 г.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZIMH73jS_ZI4",
   "metadata": {
    "id": "ZIMH73jS_ZI4"
   },
   "outputs": [],
   "source": [
    "aapl.loc['2022'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x_n4XmG_I7qy",
   "metadata": {
    "id": "x_n4XmG_I7qy"
   },
   "source": [
    "Нарисуем график котировок закрытия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PlGUM6fs_e8e",
   "metadata": {
    "id": "PlGUM6fs_e8e"
   },
   "outputs": [],
   "source": [
    "aapl['Close'].plot.line(grid=True,title='Котировки акций компании Apple в 2016-2022 гг.');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wdzOc9rYKxA0",
   "metadata": {
    "id": "wdzOc9rYKxA0"
   },
   "source": [
    "В качестве наиболее корректного показателя стоимости (цены) акции будем применять признак `Adj Close`. \n",
    "\n",
    "__Дневной доход__ по акции равен разности текущей цены акции и цены предыдущего дня. __Дневной убыток__ по акции равен разности цены предыдущего дня и текущей цены акции. __Дневная доходность__ по акции равна разности текущей цены акции и цены предыдущего дня, деленной на цену предыдущего дня. \n",
    "\n",
    "Произведем расчет дневных доходностей акции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1UoytavU_nST",
   "metadata": {
    "id": "1UoytavU_nST"
   },
   "outputs": [],
   "source": [
    "d_close = aapl[['Adj Close']]\n",
    "d_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13vUWc5j_r6H",
   "metadata": {
    "id": "13vUWc5j_r6H"
   },
   "outputs": [],
   "source": [
    "d_pct_ch = d_close.pct_change()\n",
    "d_pct_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skL-BB51_w5E",
   "metadata": {
    "id": "skL-BB51_w5E"
   },
   "outputs": [],
   "source": [
    "d_pct_ch2 = d_close / d_close.shift(1) - 1\n",
    "d_pct_ch2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Eqg4wclb_5Bo",
   "metadata": {
    "id": "Eqg4wclb_5Bo"
   },
   "outputs": [],
   "source": [
    "d_pct_ch.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PLioCz8e_94x",
   "metadata": {
    "id": "PLioCz8e_94x"
   },
   "outputs": [],
   "source": [
    "d_pct_ch.hist(bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TD5MSjDcheYa",
   "metadata": {
    "id": "TD5MSjDcheYa"
   },
   "source": [
    "### Задание на лабораторную работу №5\n",
    "\n",
    "В соответствии с индивидуальным заданием, указанным в записной книжке команды, сделайте необходимые расчеты и постройте следующие визуализации:\n",
    "\n",
    "1. При помощи модуля `pandas_datareader` считайте котировки указанной в индивидуальным задании акции за указанный период времени. \n",
    "\n",
    "2. Визуализируйте котировки акции (столбец `Adj Close`) за весь период на графике. Подпишите оси и рисунок.\n",
    "\n",
    "3. Вычислите и визуализируйте заданный показатель акции в соответствии с индивидуальным заданием.\n",
    "\n",
    "4. Сформируйте обучающую, тестовую и валидационные выборки для обучения нейронной сети в соответствии с индивидуальным заданием. \n",
    "\n",
    "5. Постройте нейронную сеть MLP с нормализующим слоем и одним плотным скрытым слоем из 16 нейронов для прогнозирования стоимости акции и обучите ее на обучающей выборке. Оцените качество прогнозирования при помощи заданного показателя качества на тестовой выборке.\n",
    "\n",
    "6. Примените указанную в индивидуальном задании технику решения проблемы исчезающих градиентов и постройте нейронную сеть MLP с нормализующим слоем и тремя плотными скрытыми слоями из 16 нейронов для прогнозирования стоимости акции и обучите ее на обучающей выборке. Оцените качество прогнозирования при помощи заданного показателя качества для тестовой выборки.\n",
    "\n",
    "7. Постройте рекуррентную нейронную сеть с нормализующим слоем и одним скрытым слоем LSTM из 16 нейронов для прогнозирования стоимости акции и обучите ее на обучающей выборке. Оцените качество прогнозирования при помощи заданного показателя качества на тестовой выборке.\n",
    "\n",
    "8. Визуализируйте кривые обучения для трех построенных моделей на одном рисунке в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду. Используйте для визуализации относительную ошибку (ошибку обучения, деленную на начальную ошибку на первой эпохе). \n",
    "\n",
    "9. Визуализируйте весь набор данных и прогнозы трех построенных моделей для обучающей и тестовой выборок на одном рисунке (ось X – даты, ось Y – стоимость акции), подписывая оси и рисунок и создавая легенду. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kyUEqC2Zh1Uf",
   "metadata": {
    "id": "kyUEqC2Zh1Uf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab5_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
