{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQlcDy9BC5bE"
   },
   "source": [
    "# Методы машинного обучения – Лабораторная работа №6\n",
    "\n",
    "# Нейронные сети CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKlRxa2EKcTu"
   },
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCNmPhYuurZN"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tfds-nightly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXzQDlKzJII8"
   },
   "source": [
    "## Загрузка набора \"лошади или люди\" (horses_or_humans)\n",
    "\n",
    "Загрузим из __Tensorflow datasets__ набор данных `horses_or_humans`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLwF99jXJII8"
   },
   "outputs": [],
   "source": [
    "ds_train = tfds.load(\"horses_or_humans\", split='train')\n",
    "df_train = tfds.as_dataframe(ds_train)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NzRjWOcJII9"
   },
   "source": [
    "Загрузим из обучающей выборки первое изображение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbbDOs0_JII-"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hlfo2Qj-JII-"
   },
   "outputs": [],
   "source": [
    "img = Image.fromarray(df_train.iloc[0]['image'])\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmY0NLLWJII_"
   },
   "source": [
    "Изображение является цветным и использует три канала:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cldCij_2JII_"
   },
   "outputs": [],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKULnPgAJIJA"
   },
   "source": [
    "Чтобы упростить работу с изображением, перейдем к изображению с оттенками серого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqoJVCycJIJA"
   },
   "outputs": [],
   "source": [
    "img = ImageOps.grayscale(img)\n",
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq22T-itJIJD"
   },
   "source": [
    "Для визуализации будем использовать следующие функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML5t9MTsJIJD"
   },
   "outputs": [],
   "source": [
    "def plot_image(img: np.array):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    \n",
    "def plot_two_images(img1: np.array, img2: np.array):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(img1, cmap='gray')\n",
    "    ax[1].imshow(img2, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtUhoDoIJIJE"
   },
   "outputs": [],
   "source": [
    "plot_image(img=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHN23GjDJIJF"
   },
   "source": [
    "## Свертка изображения\n",
    "\n",
    "Свертка сводится к повторяющемуся матричному поэлементному умножению и суммированию, которое может быть легко реализовано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EReUTyetJIJG"
   },
   "source": [
    "### Фильтры для свертки\n",
    "\n",
    "Задача сверточного слоя — найти фильтры (ядра), которые лучше всего извлекают признаки из набора данных с изображениями.\n",
    "\n",
    "Рассмотрим следующие матрицы размерами 3x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J94gnmGMJIJH"
   },
   "outputs": [],
   "source": [
    "sharpen = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "blur = np.array([\n",
    "    [0.0625, 0.125, 0.0625],\n",
    "    [0.125,  0.25,  0.125],\n",
    "    [0.0625, 0.125, 0.0625]\n",
    "])\n",
    "\n",
    "outline = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsEO-QimJIJJ"
   },
   "source": [
    "## Реализация свертки\n",
    "\n",
    "Объявим вспомогательную функцию, которая будет вычислять размеры изображения. \n",
    "\n",
    "Например, при использовании фильтра 3x3 будем терять по одному пикселю с каждого края."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLfgupXaJIJK"
   },
   "outputs": [],
   "source": [
    "def calculate_target_size(img_size: int, kernel_size: int) -> int:\n",
    "    num_pixels = 0\n",
    "    \n",
    "    for i in range(img_size):\n",
    "        added = i + kernel_size\n",
    "        if added <= img_size:\n",
    "            num_pixels += 1\n",
    "            \n",
    "    return num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhWjObQkJIJL"
   },
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=300, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipSKvmILJIJM"
   },
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=300, kernel_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmH-VMOsJIJN"
   },
   "source": [
    "Свертка работает так:\n",
    "1. Извлекаем первую матрицу 3x3 из изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITn7drA_JIJN"
   },
   "outputs": [],
   "source": [
    "subset = np.array(img)[0:0+3, 0:0+3]\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB85fkoKJIJO"
   },
   "source": [
    "2. Производим поэлементное умножение изображения на фильтр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcGviJeUJIJP"
   },
   "outputs": [],
   "source": [
    "np.multiply(subset, sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t45idmsZJIJP"
   },
   "source": [
    "3. Суммируем элементы матрицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFV0JILWJIJQ"
   },
   "outputs": [],
   "source": [
    "np.sum(np.multiply(subset, sharpen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJGDAbfqJIJQ"
   },
   "source": [
    "Применим эту логику ко всей матрице. Нужно перебрать все допустимые строки и столбцы в изображении, а затем умножить на фильтр и просуммировать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rO-fbW1NJIJQ"
   },
   "outputs": [],
   "source": [
    "def convolve(img: np.array, kernel: np.array) -> np.array:\n",
    "    # Assuming a rectangular image\n",
    "    tgt_size = calculate_target_size(\n",
    "        img_size=img.shape[0],\n",
    "        kernel_size=kernel.shape[0]\n",
    "    )\n",
    "    # To simplify things\n",
    "    k = kernel.shape[0]\n",
    "    \n",
    "    # 2D array of zeros\n",
    "    convolved_img = np.zeros(shape=(tgt_size, tgt_size))\n",
    "    \n",
    "    # Iterate over the rows\n",
    "    for i in range(tgt_size):\n",
    "        # Iterate over the columns\n",
    "        for j in range(tgt_size):\n",
    "            # img[i, j] = individual pixel value\n",
    "            # Get the current matrix\n",
    "            mat = img[i:i+k, j:j+k]\n",
    "            \n",
    "            # Apply the convolution - element-wise multiplication and summation of the result\n",
    "            # Store the result to i-th row and j-th column of our convolved_img array\n",
    "            convolved_img[i, j] = np.sum(np.multiply(mat, kernel))\n",
    "            \n",
    "    return convolved_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BIsELxCJIJR"
   },
   "source": [
    "Применим фильтр повышения резкости в первую очередь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbbfKPNnJIJR"
   },
   "outputs": [],
   "source": [
    "img_sharpened = convolve(img=np.array(img), kernel=sharpen)\n",
    "img_sharpened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UeFEj_ZJIJR"
   },
   "source": [
    "Визуализируем исходное и полученное изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u84D24BKJIJS"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPL0QnDnJIJS"
   },
   "source": [
    "Оттенки немного отличаются, так как значения в матрице `img_sharpened` не находятся в диапазоне от 0 до 255. Можно исправить это, заменив все отрицательные значения нулями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9hXPx33JIJT"
   },
   "outputs": [],
   "source": [
    "def negative_to_zero(img: np.array) -> np.array:\n",
    "    img = img.copy()\n",
    "    img[img < 0] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XTHMdTmJIJT"
   },
   "source": [
    "Снова выполним визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWnaGvjaJIJT"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=negative_to_zero(img=img_sharpened)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf_Vbf4dJIJU"
   },
   "source": [
    "Изображение определенно выглядит более четким. \n",
    "\n",
    "Теперь сделаем изображение более размытым:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKMUJ8pcJIJU"
   },
   "outputs": [],
   "source": [
    "img_blurred = convolve(img=np.array(img), kernel=blur)\n",
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_blurred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y97n2Wk8JIJU"
   },
   "source": [
    "Матрица фильтра размытия не имеет отрицательных значений, поэтому оттенки идентичны. \n",
    "\n",
    "Наконец, давайте применим фильтр контура:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwchP8bBJIJV"
   },
   "outputs": [],
   "source": [
    "img_outlined = convolve(img=np.array(img), kernel=outline)\n",
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_outlined\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7koDfunJIJV"
   },
   "source": [
    "Этот фильтр также требует корректировки оттенков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwPXEcgqJIJV"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=negative_to_zero(img=img_outlined)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USk4BpWAJIJW"
   },
   "source": [
    "Все изображения после свертки имеют размеры 298x298. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWEKc0hcJIJW"
   },
   "outputs": [],
   "source": [
    "np.array(img_sharpened).shape, np.array(img_blurred).shape, np.array(img_outlined).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSiGu8-MJIJW"
   },
   "source": [
    "### Реализация свертки с заполнением отступа (padding) \n",
    "\n",
    "Слой TensorFlow `Conv2D` позволяет указывать для параметра `padding` значения `valid` или `same`. \n",
    "\n",
    "Первый вариант (по умолчанию) означает, что к изображениям не добавляется отступ. \n",
    "Второй вариант добавляет отступы в зависимости от размера фильтра (ядра), поэтому исходное и свернутое изображения имеют одинаковую форму. Отступы - это, по сути, просто черная рамка вокруг изображения с добавленными нулями. Нули не влияют на вычисления, так как операция свертки умножает элементы изображения на элементы фильтра. Любой множитель, умноженный на ноль, дает в результате ноль. \n",
    "\n",
    "Объявим вспомогательную функцию, которая вычисляет, насколько «толстую» границу нам нужно добавить к изображению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw41q_PjJIJX"
   },
   "outputs": [],
   "source": [
    "def get_padding_width_per_side(kernel_size: int) -> int:\n",
    "    return kernel_size // 2 # целочисленное деление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bt5OfNQBJIJX"
   },
   "outputs": [],
   "source": [
    "pad_3x3 = get_padding_width_per_side(kernel_size=3)\n",
    "pad_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GiLD-xsJIJX"
   },
   "outputs": [],
   "source": [
    "pad_5x5 = get_padding_width_per_side(kernel_size=5)\n",
    "pad_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwzrcQSGJIJY"
   },
   "source": [
    "Объявим еще одну вспомогательную функцию, задача которой добавить отступ к изображению. Функция объявляет матрицу нулей формы `(image.shape + padding * 2)`. Отступы умножаются на 2, потому что они нужны со всех сторон. Затем мы индексируем матрицу, чтобы проигнорировать заполнение, и заменяем нули фактическими значениями изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR0xGr94JIJY"
   },
   "outputs": [],
   "source": [
    "def add_padding_to_image(img: np.array, padding_width: int) -> np.array:\n",
    "    # Array of zeros of shape (img + padding_width)\n",
    "    img_with_padding = np.zeros(shape=(\n",
    "        img.shape[0] + padding_width * 2,  # Multiply with two because we need padding on all sides\n",
    "        img.shape[1] + padding_width * 2\n",
    "    ))\n",
    "    \n",
    "    # Change the inner elements\n",
    "    # For example, if img.shape = (224, 224), and img_with_padding.shape = (226, 226)\n",
    "    # keep the pixel wide padding on all sides, but change the other values to be the same as img\n",
    "    img_with_padding[padding_width:-padding_width, padding_width:-padding_width] = img\n",
    "    \n",
    "    return img_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIz6XMO7JIJZ"
   },
   "outputs": [],
   "source": [
    "img_with_padding_3x3 = add_padding_to_image(\n",
    "    img=np.array(img), \n",
    "    padding_width=pad_3x3\n",
    ")\n",
    "\n",
    "print(img_with_padding_3x3.shape)\n",
    "plot_image(img_with_padding_3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tx7o5MuJJIJZ"
   },
   "outputs": [],
   "source": [
    "img_with_padding_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZKWU3AjJIJa"
   },
   "outputs": [],
   "source": [
    "img_with_padding_5x5 = add_padding_to_image(\n",
    "    img=np.array(img), \n",
    "    padding_width=pad_5x5\n",
    ")\n",
    "\n",
    "print(img_with_padding_5x5.shape)\n",
    "plot_image(img_with_padding_5x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4yT6afNJIJa"
   },
   "outputs": [],
   "source": [
    "img_with_padding_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVo9eBDwJIJb"
   },
   "source": [
    "Применим операцию свертки к нашему изображению 302x302 (граница шириной 1 пиксель):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wq4nw2hFJIJb"
   },
   "outputs": [],
   "source": [
    "img_padded_3x3_sharpened = convolve(img=img_with_padding_3x3, kernel=sharpen)\n",
    "img_padded_3x3_sharpened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRanL9TmJIJc"
   },
   "source": [
    "В результате получается изображение размером 300x300, такое же, как и исходное. \n",
    "Построим оба изображения рядом, чтобы проверить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byf74xt3JIJc"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img, \n",
    "    img2=img_padded_3x3_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V94fiXhPJIJd"
   },
   "source": [
    "## Пулинг (pooling)\n",
    "\n",
    "Пулинг сводится к разделению 2D-массива на более мелкие фрагменты, что может быть легко реализовано.\n",
    "\n",
    "Объявим небольшой 2D-массив, который будет представлять выходные данные сверточного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UXe4DqnJIJd"
   },
   "outputs": [],
   "source": [
    "conv_output = np.array([\n",
    "    [10, 12,  8,  7],\n",
    "    [ 4, 11,  5,  9],\n",
    "    [18, 13,  7,  7],\n",
    "    [ 3, 15,  2,  2]\n",
    "])\n",
    "conv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdkS6OrGJIJe"
   },
   "source": [
    "Для пулинга нужно выбрать значения для двух гиперпараметров:\n",
    "* `pool_size` — размер области, скользящей по изображению\n",
    "* `stride` - количество пикселей, на которое область перемещается по изображению\n",
    "\n",
    "Общепринятые размеры: 2 x 2 для размера пула (`pool_size`) и 2 для шага (`stride`). \n",
    "Выбор этих значений уменьшит размер результата свертки вдвое. \n",
    "Размер пула 2 x 2 и шаг 1 уменьшат размер изображения на один пиксель, что не имеет особого смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4wRsB-HJIJe"
   },
   "outputs": [],
   "source": [
    "# Define paramters\n",
    "pool_size = 2\n",
    "stride = 2\n",
    "\n",
    "# For all rows with the step size of 2 (row 0 and row 2)\n",
    "for i in np.arange(conv_output.shape[0], step=stride):\n",
    "    # For all columns with the step size of 2 (column 0 and column 2)\n",
    "    for j in np.arange(conv_output.shape[0], step=stride):\n",
    "        # Get a single pool\n",
    "        mat = conv_output[i:i+pool_size, j:j+pool_size]\n",
    "        \n",
    "        # Ensure that the shape of the matrix is 2x2 (pool size)\n",
    "        if mat.shape == (pool_size, pool_size):\n",
    "            # Print it\n",
    "            print(mat)\n",
    "    # Print a new line when the code reaches the end of a single row block\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6QK1hlrJIJe"
   },
   "source": [
    "Оформим все это в виде функции: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UME3oErBJIJf"
   },
   "outputs": [],
   "source": [
    "def get_pools(img: np.array, pool_size: int, stride: int) -> np.array:\n",
    "    # To store individual pools\n",
    "    pools = []\n",
    "    \n",
    "    # Iterate over all row blocks (single block has `stride` rows)\n",
    "    for i in np.arange(img.shape[0], step=stride):\n",
    "        # Iterate over all column blocks (single block has `stride` columns)\n",
    "        for j in np.arange(img.shape[0], step=stride):\n",
    "            \n",
    "            # Extract the current pool\n",
    "            mat = img[i:i+pool_size, j:j+pool_size]\n",
    "            \n",
    "            # Make sure it's rectangular - has the shape identical to the pool size\n",
    "            if mat.shape == (pool_size, pool_size):\n",
    "                # Append to the list of pools\n",
    "                pools.append(mat)\n",
    "                \n",
    "    # Return all pools as a Numpy array\n",
    "    return np.array(pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "outcQ46GJIJf"
   },
   "outputs": [],
   "source": [
    "test_pools = get_pools(img=conv_output, pool_size=2, stride=2)\n",
    "test_pools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_h-4JHpJIJf"
   },
   "source": [
    "### Макс-пулинг (MaxPooling) \n",
    "\n",
    "`MaxPooling` — самый распространенный тип пулинга, сохраняющий только самое большое значение из одного пула.\n",
    "\n",
    "**Логика макс-пулинга**\n",
    "1. Получить общее количество пулов - длину матрицы `pools` (или `shape[0]`)\n",
    "2. Рассчитать целевую форму - размер изображения после выполнения операции объединения.\n",
    "     - Рассчитывается как: квадратный корень из числа пулов, представленных как целое число.\n",
    "     - Если `num_pools` равно 16, то нужна матрица 4x4 (sqrt(16) = 4)\n",
    "3. Перебрать все пулы и вычислить максимальное значение — добавить максимальное значение в список результатов.\n",
    "4. Вернуть результат в виде массива Numpy, преобразованного в целевую форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND3KcOFHJIJg"
   },
   "outputs": [],
   "source": [
    "def max_pooling(pools: np.array) -> np.array:\n",
    "    # Total number of pools\n",
    "    num_pools = pools.shape[0]\n",
    "    # Shape of the matrix after pooling - Square root of the number of pools\n",
    "    # Cast it to int, as Numpy will return it as float\n",
    "    # For example -> np.sqrt(16) = 4.0 -> int(4.0) = 4\n",
    "    tgt_shape = (int(np.sqrt(num_pools)), int(np.sqrt(num_pools)))\n",
    "    # To store the max values\n",
    "    pooled = []\n",
    "    \n",
    "    # Iterate over all pools\n",
    "    for pool in pools:\n",
    "        # Append the max value only\n",
    "        pooled.append(np.max(pool))\n",
    "        \n",
    "    # Reshape to target shape\n",
    "    return np.array(pooled).reshape(tgt_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2sAjJTFJIJg"
   },
   "outputs": [],
   "source": [
    "max_pooling(pools=test_pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76tCjqy4JIJh"
   },
   "source": [
    "### Пулинг на реальном изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmM8FQHxJIJh"
   },
   "outputs": [],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6IBXeVOJIJh"
   },
   "outputs": [],
   "source": [
    "img_pools = get_pools(img=np.array(img), pool_size=2, stride=2)\n",
    "img_pools.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DRLZ8FlJIJi"
   },
   "outputs": [],
   "source": [
    "max_pooled = max_pooling(pools=img_pools)\n",
    "max_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhlh7BX-JIJi"
   },
   "outputs": [],
   "source": [
    "plot_two_images(img1=img, img2=max_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee5IyilXJIJi"
   },
   "source": [
    "Изображение справа отображается в том же размере, что и изображение слева, несмотря на то, что оно меньше — проверьте значения по осям X и Y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnzja39-JIJj"
   },
   "source": [
    "### Пулинг при помощи TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba_Zb59mJIJj"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrOvjN4IJIJj"
   },
   "source": [
    "Эту модель не нужно обучать. Но нужно изменить форму изображения, приведя ее к формату: \n",
    "* (batch size, width, height, number of color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RspB91FdJIJk"
   },
   "outputs": [],
   "source": [
    "img_arr = np.array(img).reshape(1, 300, 300, 1)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl_YSsPYJIJk"
   },
   "source": [
    "Можно воспользоваться методом `predict()`, чтобы применить пулинг. Будет возвращен тензор размеров 1x150x150x1, поэтому нужно изменить его форму на 150x150:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYCuzhaKJIJk"
   },
   "outputs": [],
   "source": [
    "output = model.predict(img_arr).reshape(150, 150)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp1zmF2LJIJl"
   },
   "source": [
    "При помощи функции `array_equal()` из Numpy можно проверить, что два массива равны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PICA3rUJIJl"
   },
   "outputs": [],
   "source": [
    "np.array_equal(max_pooled, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFZvnVhNJIJm"
   },
   "source": [
    "## Набор \"лошади или люди\" (horses_or_humans)\n",
    "\n",
    "Вернемся к набору данных `horses_or_humans` и создадим обучающие и тестовые наборы данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXaB6Od9hQMH"
   },
   "outputs": [],
   "source": [
    "ds = tfds.load(\"horses_or_humans\", split=['train','test'])\n",
    "df_train = tfds.as_dataframe(ds[0])\n",
    "df_test  = tfds.as_dataframe(ds[1])\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMPw3kmyJIJo"
   },
   "outputs": [],
   "source": [
    "df_train.iloc[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpshtWpyJIJp"
   },
   "outputs": [],
   "source": [
    "train_labels = df_train['label'].to_numpy(dtype=np.float32)\n",
    "test_labels = df_test['label'].to_numpy(dtype=np.float32)\n",
    "train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9CrdoxhJIJp"
   },
   "outputs": [],
   "source": [
    "train_images = np.zeros(shape=(df_train.shape[0],300,300,3), dtype=np.float32)\n",
    "test_images  = np.zeros(shape=(df_test.shape[0],300,300,3), dtype=np.float32)\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDyW3nkyJIJq"
   },
   "outputs": [],
   "source": [
    "for idx in range(train_labels.shape[0]):\n",
    "    train_images[idx,:,:,:] = np.array(Image.fromarray(df_train.iloc[idx]['image']))\n",
    "\n",
    "for idx in range(test_labels.shape[0]):\n",
    "    test_images[idx,:,:,:] = np.array(Image.fromarray(df_test.iloc[idx]['image']))\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFjL0jdYk2R9"
   },
   "outputs": [],
   "source": [
    "train_images /= 255\n",
    "test_images  /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkkXj3s2JIJs"
   },
   "source": [
    "## Визуализация изображений\n",
    "\n",
    "Всегда рекомендуется визуализировать некоторые изображения при работе с наборами данных изображений.\n",
    "Функция ниже отображает случайное подмножество из 10 изображений набора данных в сетке из 2 строк и 5 столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwuPYpkWJIJs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_random_sample(images):\n",
    "    n = 10\n",
    "    imgs = random.sample(list(images), n)\n",
    "    \n",
    "    num_row = 2\n",
    "    num_col = 5 \n",
    "\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(3.5 * num_col, 3 * num_row))\n",
    "    # For every image\n",
    "    for i in range(num_row * num_col):\n",
    "        # Read the image\n",
    "        img = imgs[i] \n",
    "        # Display the image\n",
    "        ax = axes[i // num_col, i % num_col]\n",
    "        ax.imshow(img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yh5qRTUJIJs"
   },
   "outputs": [],
   "source": [
    "plot_random_sample(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNiNNY9WJIJt"
   },
   "source": [
    "## Обучение нейронной сети MLP\n",
    "\n",
    "В качестве функции потерь используется бинарная кросс-энтропия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGB-WPzIJIJt"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(300, 300, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8EztFJFJIJu"
   },
   "source": [
    "## Показатели качества модели\n",
    "\n",
    "Визуализируем потери на обучающей и тестовой выборках и долю верных ответов (accuracy) на обучающей и тестовой выборках. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FU1xnBOTJIJu"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (18, 8)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCkv3xrbJIJu"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 51), history_1.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 51), history_1.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w2s209yJIJu"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 51), history_1.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(np.arange(1, 51), history_1.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33GAqJX6JIJv"
   },
   "source": [
    "Показатели качества модели весьма средние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16oHabR2JIJv"
   },
   "source": [
    "## Обучение сверточной модели\n",
    "\n",
    "Как и в случае с обычных нейросетей (с плотными слоями), сверточные нейронные сети требуют экспериментов.\n",
    "Заранее не известно, сколько сверточных слоев понадобится, какое идеальное количество фильтров для каждого слоя и каков оптимальный размер ядра.\n",
    "\n",
    "За сверточными слоями обычно следует слой пулинга, чтобы уменьшить размер изображения.\n",
    "После сверточных слоев  нужно обязательно добавить слой `Flatten`.\n",
    "Далее следуют плотные слои.\n",
    "\n",
    "Следует правильно выбрать выходной слой и функцию потерь.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKXHfss9JIJv"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), input_shape=(300, 300, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak43qebeJIJv"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 16), history_2.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 16), history_2.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVsOfQykJIJw"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 16), history_2.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(np.arange(1, 16), history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvrOTmXEBUVS"
   },
   "source": [
    "#### Задание (10 баллов)\n",
    "\n",
    "Для закрепленного за Вами варианта лабораторной работы:\n",
    "\n",
    "1. Загрузите заданный в индивидуальном задании набор данных с изображениями из Tensorflow Datasets с разбиением на обучающую и тестовую выборки.\n",
    "\n",
    "2. Визуализируйте несколько изображений, отобранных случайным образом из обучающей выборки.\n",
    "\n",
    "3. Оставьте в наборе изображения двух классов, указанных в индивидуальном задании первыми. Обучите нейронные сети MLP и CNN задаче бинарной классификации изображений (архитектура сетей по вашему усмотрению).  \n",
    "\n",
    "4. Постройте кривые обучения нейронных сетей бинарной классификации для показателей ошибки и доли верных ответов в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду.\n",
    "\n",
    "5. Сравните качество бинарной классификации нейронными сетями при помощи матрицы ошибок для тестовой выборки. \n",
    "\n",
    "6. Визуализируйте ROC-кривые для построенных классификаторов на одном рисунке (с легендой) и вычислите площади под ROC-кривыми.\n",
    "\n",
    "7. Оставьте в наборе изображения трех классов, указанных в индивидуальном задании. Обучите нейронные сети MLP и CNN задаче многоклассовой классификации изображений (архитектура сетей по вашему усмотрению). \n",
    "\n",
    "8. Сравните качество многоклассовой классификации нейронными сетями при помощи матрицы ошибок (для трех классов) для тестовой выборки. \n",
    "\n",
    "9. Постройте кривые обучения нейронных сетей многоклассовой классификации для показателей ошибки и доли верных ответов в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ul5EHxsDZgp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
