{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef53371e",
   "metadata": {},
   "source": [
    "# Методы машинного обучения – Лабораторная работа №3\n",
    "\n",
    "# Основы Tensorflow\n",
    "\n",
    "__TensorFlow__ — открытый фреймворк (библиотека) для построения и тренировки нейронных сетей для решения задач машинного обучения.\n",
    "\n",
    "TensorFlow был изначально разработан компанией Google для внутренних целей, но потом переведен в свободный доступ.\n",
    "\n",
    "Основным языком для работы с TensorFlow является __Python__, компания Google также поддерживает версии TensorFlow для __C++__ и __Java__. Развивается реализация __TensorFlow.js__ для языка __JavaScript__, была в разработке версия __Swift for Tensorflow__ для языка __Swift__. Также развивается проект __TensorFlow Lite__, представляющий собой набор инструментов, обеспечивающих машинное обучение на мобильных устройствах (для языков Java, Swift, Objective-C, C++ и Python). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1119c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb63756",
   "metadata": {},
   "source": [
    "Главным в TensorFlow является возможность т.н. __дифференцируемого программирования__ (differentiable programming). \n",
    "\n",
    "Дифференцируемое программирование позволяет автоматически вычислять производные функций в программе на языке программирования высокого уровня. Это позволяет оптимизировать параметры программы при помощи градиентных методов (градиентного спуска). Дифференцируемое программирование активно применяется при обучении нейронных сетей, в вероятностном программировании и байесовском выводе. \n",
    "\n",
    "Большинство фреймворков дифференцируемого программирования работают путем построения графа, содержащего поток управления и структуры данных. Наиболее известные реализации обычно делят на две группы:\n",
    "\n",
    "* Подходы на основе __статических__ (скомпилированных) __графов__ (TensorFlow версии 1, Theano, MXNet), как правило, обеспечивают хорошую оптимизацию компилятора и более легкое масштабирование до больших систем, но их статический характер ограничивает интерактивность и типы программ, которые можно легко создать (например, программы, включающие циклы или рекурсию), а также усложняют пользователям задачу разработки и отладки программы. \n",
    "* Подходы на основе __динамических графов__ (TensorFlow версии 2, PyTorch, AutoGrad) упрощают разработку и анализ  программ, однако приводят к накладным расходам интерпретатора, снижению масштабируемости и снижению эффективности оптимизации компилятора.\n",
    "\n",
    "Отличительными особенностями TensorFlow являются:\n",
    "\n",
    "* Эффективное выполнение низкоуровневых тензорных операций на CPU, GPU или TPU.\n",
    "* Вычисление градиента произвольных дифференцируемых выражений.\n",
    "* Масштабирование вычислений на множество устройств, таких как кластеры графических процессоров.\n",
    "* Экспорт моделей («графов») во внешние среды выполнения (серверы, браузеры, мобильные и встроенные устройства)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c7ac3",
   "metadata": {},
   "source": [
    "## Тензоры\n",
    "\n",
    "Тензоры в TensorFlow представляют собой многомерные массивы элементов одного типа и весьма похожи на массивы в NumPy. Все тензоры являются неизменяемыми (immutable) объектами как числа и строки в Python – нельзя изменить содержимое тензора, но можно создать новый тензор. \n",
    "\n",
    "Тензоры имеют свойства, аналогичные свойствам массивов NumPy: \n",
    "* `dtype`: тип элементов тензора.\n",
    "* `ndim`: ранг или количество  измерений (осей) тензора. Скаляр имеет ранг 0, вектор имеет ранг 1, матрица имеет ранг 2.\n",
    "* `shape`: форма тензора (длина (количество элементов) для каждого из измерений тензора).\n",
    "* `size`: общее количество элементов в тензоре, произведение чисел в `shape`.\n",
    "\n",
    "### Создание тензоров\n",
    "\n",
    "Рассмотрим примеры тензоров. Начнем со __скалярного тензора__ или тензора __ранга 0__. Скалярный тензор содержит единственное значение, у него нет измерений с индексами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15c832",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_0_tensor = tf.constant(2023)\n",
    "print(rank_0_tensor)\n",
    "rank_0_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d64e1",
   "metadata": {},
   "source": [
    "По умолчанию тип тензора – целое число `int32`. \n",
    "\n",
    "__Вектор__ или тензор __ранга 1__ напоминает список значений. Вектор имеет одну ось (измерение):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a68bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1_tensor = tf.constant([1., 4., 9., 16., 25.])\n",
    "print(rank_1_tensor)\n",
    "rank_1_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191c9cb",
   "metadata": {},
   "source": [
    "Тип тензора `float32` определился по значениям в списке.\n",
    "\n",
    "__Матрица__ или тензор __ранга 2__ имеет две оси (измерения):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd21655",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_2_tensor = tf.constant([[1, 2],\n",
    "                             [3, 4],\n",
    "                             [5, 6]], dtype=tf.float16)\n",
    "print(rank_2_tensor)\n",
    "rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b03d6",
   "metadata": {},
   "source": [
    "Здесь тип тензора `float16` явно указан при создании тензора.\n",
    "\n",
    "Тензоры могут иметь более чем два измерения. Например, тензор с тремя измерениями (куб):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7065bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_3_tensor = tf.constant([\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]],\n",
    "  [[7, 8, 9],\n",
    "   [10, 11, 12]],\n",
    "  [[13, 14, 15],\n",
    "   [16, 17, 18]],\n",
    "  [[19, 20, 21],\n",
    "   [22, 23, 24]]\n",
    "])\n",
    "\n",
    "print(rank_3_tensor)\n",
    "rank_3_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e8650",
   "metadata": {},
   "source": [
    "Тензор можно преобразовать в массив NumPy либо с помощью функции `np.array()`, либо с помощью метода `numpy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd2a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rank_2_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec247594",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_2_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb38349",
   "metadata": {},
   "source": [
    "Тензоры, как правило, содержат числа с плавающей точкой или целые числа, но могут иметь элементы других типов, в том числе:\n",
    "* комплексные числа\n",
    "* строки\n",
    "\n",
    "Для преобразования тензора к другому типу можно использовать функцию `tf.cast`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(rank_1_tensor, dtype=tf.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46938d0c",
   "metadata": {},
   "source": [
    "Базовый класс `tf.Tensor` требует, чтобы тензоры были «прямоугольными», то есть вдоль каждой оси все элементы имели одинаковый размер. Однако существуют специализированные типы тензоров, которые могут обрабатывать данные различных форм, например, рваные тензоры (RaggedTensor) и разреженные тензоры (SparseTensor).\n",
    "\n",
    "Тензоры могут создаваться различными функциями, аналогичными функциям в NumPy, например:\n",
    "* `tf.zeros()` – тензор из нулей\n",
    "* `tf.zeros_like()` – тензор из нулей заданной формы (shape)\n",
    "* `tf.ones()` – тензор из единиц\n",
    "* `tf.ones_like()` – тензор из единиц заданной формы (shape)\n",
    "* `tf.eye()` – тензор для единичной матрицы\n",
    "* `tf.fill()` – тензор заданной формы (shape) с элементами, равными заданному скалярному значению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6857cf74",
   "metadata": {},
   "source": [
    "### Операции над тензорами\n",
    "\n",
    "Над тензорами можно выполнять базовые математические операции, включая сложение, поэлементное умножение и матричное умножение. Для этого можно использовать функции Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7fe732",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(np.arange(9).reshape(3,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a906376",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.ones((3,3),dtype=tf.int64)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc080eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.add(a, b), \"\\n\")\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "print(tf.matmul(a, b), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfb9c4",
   "metadata": {},
   "source": [
    "Tensorflow также выполняет перегрузку многих математических и логических операторов, например:\n",
    "\n",
    "    z = -x  # z = tf.negative(x)\n",
    "    z = x + y  # z = tf.add(x, y)\n",
    "    z = x - y  # z = tf.subtract(x, y)\n",
    "    z = x * y  # z = tf.mul(x, y)\n",
    "    z = x / y  # z = tf.div(x, y)\n",
    "    z = x // y  # z = tf.floordiv(x, y)\n",
    "    z = x % y  # z = tf.mod(x, y)\n",
    "    z = x ** y  # z = tf.pow(x, y)\n",
    "    z = x @ y  # z = tf.matmul(x, y)\n",
    "    z = x > y  # z = tf.greater(x, y)\n",
    "    z = x >= y  # z = tf.greater_equal(x, y)\n",
    "    z = x < y  # z = tf.less(x, y)\n",
    "    z = x <= y  # z = tf.less_equal(x, y)\n",
    "    z = abs(x)  # z = tf.abs(x)\n",
    "    z = x & y  # z = tf.logical_and(x, y)\n",
    "    z = x | y  # z = tf.logical_or(x, y)\n",
    "    z = x ^ y  # z = tf.logical_xor(x, y)\n",
    "    z = ~x  # z = tf.logical_not(x)\n",
    "\n",
    "Поэтому указанные выше тензоры можно также получить следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27139f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a + b, \"\\n\") # поэлементное сложение\n",
    "print(a * b, \"\\n\") # поэлементное умножение\n",
    "print(a @ b, \"\\n\") # матричное умножение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d9fe2",
   "metadata": {},
   "source": [
    "Тензоры можно использовать во всех операциях Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a76fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "\n",
    "print(tf.reduce_max(c))  # максимальное значение\n",
    "\n",
    "print(tf.argmax(c))      # индекс максимального значения\n",
    "\n",
    "print(tf.nn.softmax(c))  # вычислить функцию softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d98322",
   "metadata": {},
   "source": [
    "### Индексирование в Tensorflow\n",
    "\n",
    "TensorFlow следует стандартным правилам индексации Python и основным правилам индексации NumPy:\n",
    "* индексы начинаются с 0\n",
    "* отрицательные индексы отсчитываются в обратном порядке с конца\n",
    "* двоеточия `:` используются для срезов: `start:stop:step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2c4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_1_tensor = tf.constant(range(10))\n",
    "print(rank_1_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01321b7",
   "metadata": {},
   "source": [
    "Индексирование тензора при помощи конкретного значения индекса не сохраняет измерение (ось) тензора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c8b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Первый элемент:\", rank_1_tensor[0].numpy())\n",
    "print(\"Второй элемент:\", rank_1_tensor[1].numpy())\n",
    "print(\"Последний эл-т:\", rank_1_tensor[-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dffd012",
   "metadata": {},
   "source": [
    "Индексирование с использованием срезов сохраняет измерение (ось):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b95db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Все элементы:\", rank_1_tensor[:].numpy())\n",
    "print(\"До 4-го элемента:\", rank_1_tensor[:4].numpy())\n",
    "print(\"От 5-го элемента до конца:\", rank_1_tensor[4:].numpy())\n",
    "print(\"От 3-го до 7 элемента:\", rank_1_tensor[2:7].numpy())\n",
    "print(\"Через один элемент:\", rank_1_tensor[::2].numpy())\n",
    "print(\"В обратном порядке:\", rank_1_tensor[::-1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698983ff",
   "metadata": {},
   "source": [
    "Тензоры более высокого ранга индексируются использованием нескольких индексов.\n",
    "Те же самые правила, что и в случае одного измерения, применяются к каждому измерению (оси) независимо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ced2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rank_2_tensor.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8426b47",
   "metadata": {},
   "source": [
    "При использовании целого числа для каждого индекса получаем скаляр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0488445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rank_2_tensor[1, 1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c805a",
   "metadata": {},
   "source": [
    "Можно использовать любую комбинацию целых индексов и срезов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Вторая строка:\", rank_2_tensor[1, :].numpy())\n",
    "print(\"Второй столбец:\", rank_2_tensor[:, 1].numpy())\n",
    "print(\"Последняя строка:\", rank_2_tensor[-1, :].numpy())\n",
    "print(\"Первый элемент последнего столбца:\", rank_2_tensor[0, -1].numpy())\n",
    "print(\"Пропустить первую строку:\\n\", rank_2_tensor[1:, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90caeade",
   "metadata": {},
   "source": [
    "### Изменение формы тензоров\n",
    "\n",
    "Иногда изменение формы тензора является необходимым при проведении вычислений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ed21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1], [2], [3]])\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f37c4",
   "metadata": {},
   "source": [
    "Вообще говоря, форма тензора является объектом класса `TensorShape`, но этот объект  допускает индексирование и может быть преобразован в список:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160714b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape[0],x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d292c12",
   "metadata": {},
   "source": [
    "Можно преобразовать тензор к другой форме. Функция `tf.reshape()` выполняется быстро и эффективно, поскольку данные тензора не нужно дублировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e20cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshaped = tf.reshape(x, [1, 3]) # можно использовать кортеж (1, 3)\n",
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7824f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(x_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3860ed1",
   "metadata": {},
   "source": [
    "При изменении формы тензора данные сохраняются в памяти, и создается новый тензор с новой формой, указывающий на те же данные. TensorFlow использует упорядочение памяти по строкам в стиле языка `C`, где увеличение самого правого индекса соответствует одному шагу в памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671cb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rank_3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda0822",
   "metadata": {},
   "source": [
    "Если выпрямить тензор (указав форму `[-1]`), то можно увидеть, в каком порядке он расположен в памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac660e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reshape(rank_3_tensor, [-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa970c75",
   "metadata": {},
   "source": [
    "Обычно `tf.reshape()` используется для объединения или разделения соседних осей (или добавления или удаления измерений (осей) длиной 1).\n",
    "Для тензора 4x2x3 возможно изменение формы до (4x2)x3 или 4x(2x3), поскольку при этом срезы не смешиваются:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e91f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reshape(rank_3_tensor, [8, 3]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [4, -1]), \"\\n\")\n",
    "print(tf.reshape(rank_3_tensor, [-1, 4]), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae218b",
   "metadata": {},
   "source": [
    "Изменение формы тензора возможно для любой формы с тем же общим количеством элементов, но оно не принесет ничего полезного, если не соблюдается порядок осей.\n",
    "Перестановка измерений (осей) при помощи `tf.reshape()` не работает – для этого нужно использовать `tf.transpose()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb230970",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reshape(rank_3_tensor, [4, 3, 2])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c06eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.reshape(rank_3_tensor, [6, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  tf.reshape(rank_3_tensor, [7, -1])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5f416",
   "metadata": {},
   "source": [
    "## Переменные Tensorflow\n",
    "\n",
    "Переменная TensorFlow представляет собой объект для хранения переменных данных, которые изменяют свое значение и оптимизируются в ходе обучения нейронной сети.  \n",
    "\n",
    "Переменные в TensorFlow создаются и отслеживаются с помощью класса `tf.Variable`. Экземпляры класса `tf.Variable` представляют собой тензоры, значения которых можно изменять, применив к ним функции. Модули более высокого уровня, такие как `tf.keras`, используют объекты `tf.Variable` для хранения параметров модели нейронной сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776cb5c",
   "metadata": {},
   "source": [
    "### Создание переменных\n",
    "\n",
    "Чтобы создать переменную TensorFlow, необходимо указать ее начальное значение, причем объект `tf.Variable` будет иметь тот же тип `dtype`, что и значение инициализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e0e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "my_variable = tf.Variable(my_tensor)\n",
    "my_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c52aa30",
   "metadata": {},
   "source": [
    "Переменные, как и тензоры, могут иметь различные типы (включая логический и комплексный типы):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714c442",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_variable = tf.Variable([False, False, False, True])\n",
    "bool_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e40b6c",
   "metadata": {},
   "source": [
    "Переменная TensorFlow используется как тензор и, по сути, является структурой данных для хранения объекта `tf.Tensor`. У переменных, как и у тензоров, есть тип (`dtype`) и форма (`shape`), и их можно экспортировать в NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494506e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Форма:\", my_variable.shape)\n",
    "print(\"Тип:  \", my_variable.dtype)\n",
    "print(\"NumPy:\", my_variable.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45a78a0",
   "metadata": {},
   "source": [
    "Большинство тензорных операций применимо к переменным TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2900c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Переменная:\", my_variable)\n",
    "print(\"\\nПреобразована в тензор:\", tf.convert_to_tensor(my_variable))\n",
    "print(\"\\nИндекс максимального значения:\", tf.argmax(my_variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e56adb",
   "metadata": {},
   "source": [
    "Переменные не могут изменить форму, точнее при изменении формы возвращается новый объект (тензор):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec037dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nИзменение формы: \", tf.reshape(my_variable, [1,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec07b57",
   "metadata": {},
   "source": [
    "Как отмечалось выше, переменные хранят тензоры. Можно переназначить тензор, связанный с переменной, используя метод `assign()`. Вызов метода `assign()` обычно не создает новый тензор, вместо этого повторно используется память существующего тензора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4883b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_variable = tf.Variable([2.0, 3.0])\n",
    "a_variable.assign([1, 2])\n",
    "a_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48a03c",
   "metadata": {},
   "source": [
    "Обратите внимание, что сохранился тип переменной `float32`. Форма переменной не может быть изменена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  a_variable.assign([1.0, 2.0, 3.0])\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7c59e",
   "metadata": {},
   "source": [
    "Создание новых переменных из существующих создает копии тензоров, т.е. две переменные не будут использовать одни и те же ячейки памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_var = tf.Variable([2.0, 3.0])\n",
    "b_var = tf.Variable(a_var)\n",
    "a_var.assign([5, 6])\n",
    "\n",
    "print('a =', a_var.numpy())\n",
    "print('b =', b_var.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5125cd0f",
   "metadata": {},
   "source": [
    "Также могут использоваться другие версии метода `assign`, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_var.assign_add([2,3]).numpy())  # добавление\n",
    "print(a_var.assign_sub([7,9]).numpy())  # вычитание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6f8bc1",
   "metadata": {},
   "source": [
    "### Имена переменных\n",
    "\n",
    "Объект класса `tf.Variable` имеет тот же жизненный цикл, что и другие объекты Python. Когда отсутствуют ссылки на переменную, она автоматически освобождается.\n",
    "\n",
    "Переменные TensorFlow могут иметь имена (`name`), что помогает в отслеживании и отладке переменных. Двум переменным может быть дано одно и то же имя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_var = tf.Variable(my_tensor, name=\"Test\")\n",
    "b_var = tf.Variable(my_tensor + 1, name=\"Test\")\n",
    "print('\\na =', a_var)\n",
    "print('\\nb =', b_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfaa09",
   "metadata": {},
   "source": [
    "К указанному в конструкторе имени переменной добавляется текст `\":0\"`, что связано с тем, что конструктор класса вернул одну переменную. Когда функция TensorFlow будет возвращать несколько переменных, к имени будет добавляться текст `\":0\"`, `\":1\"` и т.д. Хотя две созданные переменные имеют одно и то же имя, они не рассматриваются как равные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a_var == b_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbd95b",
   "metadata": {},
   "source": [
    "По умолчанию переменные автоматически получают уникальные имена, поэтому не нужно назначать их самостоятельно, если имена переменных не будут использоваться в программе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728202f5",
   "metadata": {},
   "source": [
    "## Вычисление градиентов\n",
    "\n",
    "Обучение нейронных сетей обычно основывается на градиентных методах. Чтобы вычислить градиент, TensorFlow  запоминает, какие операции и в каком порядке происходят во время прямого прохода по нейронной сети. Затем, TensorFlow проходит узлы нейронной сети в обратном порядке для вычисления градиента.\n",
    "\n",
    "Для запоминания операций в TensorFlow используется __лента__ – класс `tf.GradientTape`. В качестве простого примера рассмотрим вычисление градиента (производной) функции $y = x^2$ в точке $x = 5$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53929414",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(5.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f437f",
   "metadata": {},
   "source": [
    "После того, как операции записаны, можно использовать метод `GradientTape.gradient(target, sources)` для вычисления градиента некоторой функции (цели) `target` относительно источников (переменных) `sources`. В нашем случае производная функции $y(x)$ по $x$ в точке $x = 5$ равна $\\frac{dy}{dx} = 2 x = 10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "dydx = tape.gradient(y, x)\n",
    "dydx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a482e2",
   "metadata": {},
   "source": [
    "В приведенном выше примере использовались скалярные величины, но класс `tf.GradientTape` так же легко работает с любым тензором:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random.normal((3, 2)), name='w')       # случайная матрица весов 3 x 2\n",
    "b = tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')  # вектор смещений из 2х элементов\n",
    "x = [[1., 2., 3.]]                                        # вектор значений из 3х элементов\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:            # постоянная лента градиента\n",
    "  y = x @ w + b                                           # y - вектор из 2х элементов\n",
    "  loss = tf.reduce_mean(y**2)                             # среднее арифметическое квадратов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f53158",
   "metadata": {},
   "source": [
    "Чтобы получить градиент `loss` по обеим переменным TensorFlow ($w$ и $b$), нужно передать их в качестве источников методу для вычисления градиента. Лента (`tape`) обладает гибкостью в отношении формата источников и будет принимать любую вложенную комбинацию списков или словарей и возвращать градиент, структурированный таким же образом. Например, можно использовать список:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e8055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dldw, dldb = tape.gradient(loss, [w, b])\n",
    "print('\\ndl/dw =', dldw)\n",
    "print('\\ndl/db =', dldb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ae0b2",
   "metadata": {},
   "source": [
    "Можно расчитать градиент по словарю переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e28e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vars = {'w': w, 'b': b}\n",
    "\n",
    "grad = tape.gradient(loss, my_vars)\n",
    "print('w ->', grad['w'])\n",
    "print('b ->', grad['b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d60f64",
   "metadata": {},
   "source": [
    "По умолчанию ресурсы, удерживаемые лентой (`GradientTape`), освобождаются, как только вызывается метод `GradientTape.gradient()`, то есть объект `GradientTape` исчезнет после того, как вы используете его для расчета градиента.\n",
    "\n",
    "Чтобы проиллюстрировать это, настроим градиентную ленту как обычно и рассчитаем градиент, чтобы градиентная лента была «истекшей»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "# По умолчанию persistent = False \n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    \n",
    "    y = x * x    # y = x^2\n",
    "    z = y * y    # z = y^2\n",
    "\n",
    "# Вычислим  dz/dx = 4 * x^3 в точке x = 3 --> 108.0\n",
    "dz_dx = t.gradient(z, x)\n",
    "print(dz_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034881d",
   "metadata": {},
   "source": [
    "Если попытаемся рассчитать еще один градиент после того, как градиентная лента уже была  использована, то получим ошибку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b4cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    dy_dx = t.gradient(y, x)  # 6.0\n",
    "    print(dy_dx)\n",
    "except RuntimeError as e:\n",
    "    print(\"Получена ошибка:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec57314",
   "metadata": {},
   "source": [
    "Чтобы вычислить несколько градиентов по одной ленте, можно создать постоянную ленту градиента (с параметром `persistent=True`). Это позволяет многократно вызывать метод градиента:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5b8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "    t.watch(x)\n",
    "    \n",
    "    y = x * x    # y = x^2\n",
    "    z = y * y    # z = y^2\n",
    "\n",
    "# Вычислим  dz/dx = 4 * x^3 в точке x = 3 --> 108.0\n",
    "dz_dx = t.gradient(z, x)\n",
    "print(dz_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695c88b9",
   "metadata": {},
   "source": [
    "Вычислим второй градиент на этой постоянной ленте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_dx = t.gradient(y, x)  # 6.0\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be547651",
   "metadata": {},
   "source": [
    "Ресурсы ленты высвобождаются, когда объект ленты удаляется сборщиком мусора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0025694",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tape # удаляем ссылку на ленту"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb7e4e9",
   "metadata": {},
   "source": [
    "### Управление лентой\n",
    "\n",
    "Поведение ленты по умолчанию — это записывать все операции после использования обучаемой переменной класса  `tf.Variable`. Причинами этого являются:\n",
    "\n",
    "* Лента должна знать, какие операции записывать при прямом проходе, чтобы вычислять градиенты при обратном проходе.\n",
    "* Лента содержит ссылки на промежуточные результаты, поэтому вам не требуется записывать ненужные операции.\n",
    "* Наиболее распространенный вариант использования ленты включает вычисление градиента потерь по отношению ко всем обучаемым переменным модели.\n",
    "\n",
    "Например, в примерах ниже градиент не может быть рассчитан, потому что объект класса `tf.Tensor` по умолчанию не отслеживается лентой, а переменная `tf.Variable` может быть не обучаемой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df37e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучаемая переменная\n",
    "x0 = tf.Variable(1.0, name='x0')\n",
    "# не обучаемая переменная\n",
    "x1 = tf.Variable(1.0, name='x1', trainable=False)\n",
    "# не переменная, а тензор, т.к. переменная + значение возвращает тензор\n",
    "x2 = tf.Variable(1.0, name='x2') + 1.0\n",
    "# не переменная, а тензор\n",
    "x3 = tf.constant(3.0, name='x3')\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = (x0**2) + (x1**2) + (x2**2) + (x3**2)\n",
    "\n",
    "grad = tape.gradient(y, [x0, x1, x2, x3])\n",
    "\n",
    "for g in grad:\n",
    "  print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e049be4",
   "metadata": {},
   "source": [
    "Можно составить список из переменных, отслеживаемых лентой, используя метод `GradientTape.watched_variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e783226",
   "metadata": {},
   "outputs": [],
   "source": [
    "[var.name for var in tape.watched_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86699163",
   "metadata": {},
   "source": [
    "Лента предоставляет пользователю средства контроля над тем, что отслеживается лентой, а что нет.\n",
    "Например, чтобы записать градиенты относительно объекта класса `tf.Tensor`, нужно вызвать метод  `GradientTape.watch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03746f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2.0)             # x - тензор, а не переменная\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)                  # начинаем отслеживать x\n",
    "  y = x**3\n",
    "\n",
    "dydx = tape.gradient(y, x)       # dy/dx = 3x^2 при x=2, т.е. 12\n",
    "print('dy/dx =', dydx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e511be",
   "metadata": {},
   "source": [
    "И наоборот, чтобы отключить поведение по умолчанию с отслеживанием всех объектов класса `tf.Variables`, можно установить флажок `watch_accessed_variables=False` при создании ленты градиента. В расчете ниже используется две переменные, но отслеживается градиент только для одной из переменных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = tf.Variable(0.0)\n",
    "x1 = tf.Variable(1.0)\n",
    "\n",
    "with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "  tape.watch(x1)\n",
    "  y0 = tf.math.sin(x0)\n",
    "  y1 = tf.nn.relu(x1)\n",
    "  y = y0 + y1\n",
    "  ys = tf.reduce_sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770cb03f",
   "metadata": {},
   "source": [
    "Поскольку метод `GradientTape.watch` не вызывался для переменной `x0`, по отношению к ней градиент не вычисляется:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = tape.gradient(ys, {'x0': x0, 'x1': x1})\n",
    "\n",
    "print('dy/dx0:', grad['x0'])\n",
    "print('dy/dx1:', grad['x1'].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a620ea4c",
   "metadata": {},
   "source": [
    "Ленты `GradientTapes` можно вкладывать друг в друга для вычисления производных более высокого порядка. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    gt1.watch(x)\n",
    "    with tf.GradientTape() as gt2:\n",
    "        gt2.watch(x)\n",
    "        y = x * x\n",
    "    dydx = gt2.gradient(y, x)     # dy/dx = 2 * x\n",
    "d2ydx2 = gt1.gradient(dydx, x)  # d2y/dx2 = 2\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1be53",
   "metadata": {},
   "source": [
    "Имейте в виду, что первое вычисление градиента `dydx` должно происходить, по крайней мере, внутри внешнего блока `with`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0) # используем переменную, а не тензор\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    with tf.GradientTape() as gt2:\n",
    "        y = x * x \n",
    "    \n",
    "    dydx = gt2.gradient(y, x) # Первый градиент внутри внешнего блока 'with'\n",
    "d2ydx2 = gt1.gradient(dydx, x)\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8112848",
   "metadata": {},
   "source": [
    "Первый расчет градиента также может быть внутри внутреннего блока `with`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163bdbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    with tf.GradientTape() as gt2:\n",
    "        y = x * x \n",
    "    \n",
    "        dydx = gt2.gradient(y, x) # Первый градиент внутри внутреннего блока 'with'\n",
    "d2ydx2 = gt1.gradient(dydx, x)\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab287107",
   "metadata": {},
   "source": [
    "Если первое вычисление градиента находится за пределами внешнего блока `with`, то оно не будет сохраняться для второго вычисления градиента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    with tf.GradientTape() as gt2:\n",
    "        y = x * x \n",
    "    \n",
    "dydx = gt2.gradient(y, x)      # Первый градиент за пределами внешнего блока 'with'\n",
    "d2ydx2 = gt1.gradient(dydx, x) # Лента \"просрочена\", поэтому градиент равен 'None'\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a5081",
   "metadata": {},
   "source": [
    "Расчет `d2ydx2` теперь равен `None`, так как срок действия ленты истек. Также обратите внимание, что это по-прежнему не будет работать, даже если вы установите для обеих градиентных лент значение `persistent=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as gt1:     # 'persistent=True' не работает\n",
    "    with tf.GradientTape(persistent=True) as gt2: # 'persistent=True' не работает\n",
    "        y = x * x \n",
    "    \n",
    "dydx = gt2.gradient(y, x)      # Первый градиент за пределами внешнего блока 'with'\n",
    "d2ydx2 = gt1.gradient(dydx, x) # Лента \"просрочена\", поэтому градиент равен 'None'\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1202640",
   "metadata": {},
   "source": [
    "Итак, второе вычисление градиента `d2ydx2` может иметь такой же отступ, как и первое вычисление `dydx`, но не больше. Возможные варианты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    with tf.GradientTape() as gt2:\n",
    "        y = x * x \n",
    "    \n",
    "        dydx = gt2.gradient(y, x) \n",
    "        d2ydx2 = gt1.gradient(dydx, x)\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    with tf.GradientTape() as gt2:\n",
    "        y = x * x \n",
    "    \n",
    "        dydx = gt2.gradient(y, x) \n",
    "    d2ydx2 = gt1.gradient(dydx, x)\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29fd599",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "with tf.GradientTape() as gt1:\n",
    "    with tf.GradientTape() as gt2:\n",
    "        y = x * x \n",
    "    \n",
    "        dydx = gt2.gradient(y, x) \n",
    "d2ydx2 = gt1.gradient(dydx, x)\n",
    "\n",
    "print('dy/dx =', dydx)\n",
    "print('d2y/dx2 =', d2ydx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359726e",
   "metadata": {},
   "source": [
    "### Использование промежуточных результатов\n",
    "\n",
    "Можно также использовать градиенты относительно промежуточных значений, вычисленных внутри контекста ленты `tf.GradientTape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ecd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  tape.watch(x)\n",
    "  y = x * x  # y = x^2\n",
    "  z = y * y  # z = y^2 = x^4\n",
    "\n",
    "print(tape.gradient(z, y).numpy())  # y = x^2 = 4, dz/dy = 2 y = 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b329a9eb",
   "metadata": {},
   "source": [
    "### Градиенты для векторных величин\n",
    "\n",
    "Градиент в TensorFlow - это принципиально операция над скалярной величиной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  y1 = x**2\n",
    "  y2 = 1 / x\n",
    "\n",
    "print('dy1/dx =', tape.gradient(y1, x).numpy())\n",
    "print('dy2/dx =', tape.gradient(y2, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94ce2c",
   "metadata": {},
   "source": [
    "Градиент от нескольких функций вычисляется как градиент суммы функций или эквивалентно как сумма градиентов каждой функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21942d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y1 = x**2\n",
    "  y2 = 1 / x\n",
    "\n",
    "print(tape.gradient({'y1': y1, 'y2': y2}, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c455c",
   "metadata": {},
   "source": [
    "Точно так же, если функция является векторной, то вычисляется градиент суммы компонентов вектора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  y = x * [3., 4.]\n",
    "  print('y =', y)\n",
    "\n",
    "print(tape.gradient(y, x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f8a7e7",
   "metadata": {},
   "source": [
    "### Ситуации, когда градиент не может быть вычислен\n",
    "\n",
    "Возможно возникновение ряда ситуаций, когда градиент не может быть вычислен.\n",
    "\n",
    "#### Поток управления\n",
    "\n",
    "Лента градиента записывает операции по мере их выполнения в соответствии с потоком управления Python (операторами `if`, `while` и т.п.).\n",
    "В примере в каждой ветви `if` используется другая переменная, но для расчета градиента  записывается только совершенная операция с переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13954d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(-1.0)\n",
    "\n",
    "v1 = tf.Variable(2.0)\n",
    "v2 = tf.Variable(2.0)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "  tape.watch(x)\n",
    "  if x > 0.0:\n",
    "    result = v1\n",
    "  else:\n",
    "    result = v2**2 \n",
    "\n",
    "dv1, dv2 = tape.gradient(result, [v1, v2])\n",
    "\n",
    "print('1 ->', dv1)\n",
    "print('2 ->', dv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08c2ae7",
   "metadata": {},
   "source": [
    "Операторы управления сами по себе не дифференцируемы и не видимы для оптимизаторов на основе градиента.\n",
    "В приведенном выше примере в зависимости от значения `x` на ленту записывается либо `result = v0`, либо `result = v1**2`. Градиент по `x` всегда равен `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = tape.gradient(result, x)\n",
    "\n",
    "print(dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6d967",
   "metadata": {},
   "source": [
    "#### Отсутствие зависимости от переменной\n",
    "\n",
    "Когда результат вычислений не связан с переменной, градиент будет равен `None`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a8137",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(1.)\n",
    "y = tf.Variable(2.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  z = y * y\n",
    "\n",
    "print(tape.gradient(z, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1895ee",
   "metadata": {},
   "source": [
    "#### Тензор вместо переменной\n",
    "\n",
    "По умолчанию лента градиента отслеживает операции с переменными, но не тензорами. Поэтому градиент не вычисляется, если по ошибке переменная заменена на тензор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1382d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0)\n",
    "\n",
    "for epoch in range(2):\n",
    "  with tf.GradientTape() as tape:\n",
    "    y = x+1\n",
    "\n",
    "  print(epoch, '->', type(x).__name__, \":\", tape.gradient(y, x))\n",
    "  x = x + 1   # правильно `x.assign_add(1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea168f0",
   "metadata": {},
   "source": [
    "#### Вычисления за пределами TensorFlow\n",
    "\n",
    "Лента не может записать вычисления, если они производятся вне TensorFlow, например, в NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e178491",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable([[1.0, 2.0],\n",
    "                 [3.0, 4.0]], dtype=tf.float32)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "  x2 = x**2\n",
    "\n",
    "  y = np.mean(x2, axis=0) # вычисления в NumPy\n",
    "\n",
    "  y = tf.reduce_mean(y, axis=0) # массив NumPy конвертируется в тензор\n",
    "\n",
    "print(tape.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d5464e",
   "metadata": {},
   "source": [
    "#### Градиент по целому числу или строке\n",
    "\n",
    "Целые числа и строки не являются дифференцируемыми в TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebb8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(10)\n",
    "\n",
    "with tf.GradientTape() as gt:\n",
    "  gt.watch(x)\n",
    "  y = x * x\n",
    "\n",
    "print(gt.gradient(y, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c91846",
   "metadata": {
    "colab_type": "text",
    "id": "K7O6eEGF5DcN"
   },
   "source": [
    "## Обучение модели парной линейной регрессии\n",
    "\n",
    "Модель парной линейной регрессии определяется как класс, где:\n",
    "- `x` - входной тензор\n",
    "- модель должна выводить значения **wx+b**\n",
    "- значения **w** и **b** инициализируются случайными значениями\n",
    "- в процессе обучения значения **w** и **b** обновляются в соответствии с линейной регрессией, чтобы минимизировать ошибку (потери) модели\n",
    "- как только будут получены оптимальные значения для **w** и **b**, модель будет обучена правильно предсказывать значения **wx+b**\n",
    "\n",
    "Итак, \n",
    "- **w** и **b** – обучаемые параметры модели \n",
    "- **x** – входные данные\n",
    "- **y = wx + b** – выходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234bb2e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WRu7Pze7wk8"
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "  def __init__(self):\n",
    "    # Инициализируем вес как `2.0` и смещение как  `1.0`\n",
    "    # На практике инициализация должна быть случайными значениями (`tf.random.normal`)\n",
    "    self.w = tf.Variable(2.0)\n",
    "    self.b = tf.Variable(1.0)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    return self.w * x + self.b\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39005925",
   "metadata": {
    "colab_type": "text",
    "id": "xa6j_yXa-j79"
   },
   "source": [
    "### Определяем функцию потерь \n",
    "\n",
    "Функция потерь измеряет, насколько хорошо результат модели для данного входа соответствует целевому результату.\n",
    "- Цель состоит в том, чтобы минимизировать эту разницу во время тренировки.\n",
    "- Будем использовать потери $L_2$, также известные как сумма наименьших квадратов.\n",
    "\n",
    "$$Loss = \\sum_{i} \\left (y_{pred}^i - y_{target}^i \\right )^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7409d3fc",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0ysUFGY924U"
   },
   "outputs": [],
   "source": [
    "def loss(predicted_y, target_y):\n",
    "  return tf.reduce_mean(tf.square(predicted_y - target_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d71e38",
   "metadata": {},
   "source": [
    "### Оценка качества регрессии\n",
    "\n",
    "Пусть $\\mathbf{Y}=\\left(y_{1},y_{2},...,y_{n}\\right)^{T}$ – вектор значений откликов, а $\\hat{\\mathbf{Y}}=\\left(\\hat{y}_{1},\\hat{y}_{2},...,\\hat{y}_{n}\\right)^{T}$ – вектор прогнозируемых значений откликов. Тогда для оценки качества регрессии можно использовать показатели:\n",
    "\n",
    "* Среднее квадратичное отклонение (Mean Squared Error, MSE)\n",
    "\n",
    "$$MSE=\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$$\n",
    "\n",
    "* Корень среднеквадратичного отклонения (Root Mean Squared Error, RMSE)\n",
    "\n",
    "$$RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}}$$\n",
    "\n",
    "* Среднее квадратичное процентное отклонение (Mean Squared Percentage Error, MSPE)\n",
    "\n",
    "$$MSPE=\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\frac{y_{i}-\\hat{y}_{i}}{y_{i}}\\right)^{2}$$\n",
    "\n",
    "* Среднее абсолютное отклонение (Mean Absolute Error, MAE)\n",
    "\n",
    "$$MAE=\\frac{1}{n}\\sum_{i=1}^{n}\\left|y_{i}-\\hat{y}_{i}\\right|$$\n",
    "\n",
    "* Среднее абсолютное процентное отклонение (Mean Average Percentage Error, MAPE) \n",
    "\n",
    "$$MAPE=\\frac{1}{n}\\sum_{i=1}^{n}\\left|\\frac{y_{i}-\\hat{y}_{i}}{y_{i}}\\right|$$\n",
    "\n",
    "* Среднее квадратичное логарифмическое отклонение (Mean Squared Logarithmic Error, MSLE)\n",
    "\n",
    "$$MSLE=\\frac{1}{n}\\sum_{i=1}^{n}\\left(\\ln\\left(1+y_{i}\\right)-\\ln\\left(1+\\hat{y}_{i}\\right)\\right)^{2}$$\n",
    "\n",
    "* Медианное абсолютное отклонение (Median Absolute Error, MedAE) \n",
    "\n",
    "$$MedAE=\\mathrm{median}\\left(\\left|y_{1}-\\hat{y}_{1}\\right|,...\\left|y_{n}-\\hat{y}_{n}\\right|\\right)$$\n",
    "\n",
    "* Максимальная ошибка (maximum residual error, MaxErr)\n",
    "\n",
    "$$MaxErr=\\max_{i=\\overline{1,n}}\\left|y_{i}-\\hat{y}_{i}\\right|$$\n",
    "\n",
    "Для реализации этих метрик качества можно использовать функции модуля `tf.math`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fac381",
   "metadata": {
    "colab_type": "text",
    "id": "qutT_fkl_CBc"
   },
   "source": [
    "### Построение обучающих данных\n",
    "\n",
    "Во-первых, синтезируем обучающие данные при помощи истинных значений $w$ и $b$:\n",
    " \n",
    "$$y = w_{true} \\times x + b_{true} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc2f2b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxPTb-kt_N5m"
   },
   "outputs": [],
   "source": [
    "TRUE_w = 3.0\n",
    "TRUE_b = 2.0\n",
    "NUM_EXAMPLES = 1000\n",
    "\n",
    "xs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "\n",
    "ys = (TRUE_w * xs) + TRUE_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878f009d",
   "metadata": {
    "colab_type": "text",
    "id": "-50nq-wPBsAW"
   },
   "source": [
    "Перед обучением модели визуализируем ошибку моделии, нанеся прогнозы модели красными крестиками, а обучающие данные  — синими точками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5946b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eb83LtrB4nt"
   },
   "outputs": [],
   "source": [
    "def plot_data(inputs, outputs, predicted_outputs):\n",
    "  real = plt.scatter(inputs, outputs, c='b', marker='.')\n",
    "  predicted = plt.scatter(inputs, predicted_outputs, c='r', marker='+')\n",
    "  plt.legend((real,predicted), ('Реальные данные', 'Прогнозируемые данные'))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a632236",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XL25a_aEOuim"
   },
   "outputs": [],
   "source": [
    "plot_data(xs, ys, model(xs))\n",
    "print('Текущие потери (ошибка): %1.6f' % loss(model(xs), ys).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00c293",
   "metadata": {
    "colab_type": "text",
    "id": "sSDP-yeq_4jE"
   },
   "source": [
    "### Определение цикла обучения\n",
    "\n",
    "Используя обучающие данные, обучим модель, используя градиентный спуск. \n",
    "Градиентный спуск обновляет обучаемые веса и смещение **w** и **b**, чтобы уменьшить потери (ошибку) модели.\n",
    "\n",
    "Существует множество вариантов схемы градиентного спуска, которые реализованы в модуле  `tf.keras.optimizers`. Реализуем здесь базовый градиентный спуск, используя `tf.GradientTape` для автоматического дифференцирования и `tf.assign_sub` для изменения значений весов и смещения (`assign_sub` объединяет `tf.assign` и `tf.sub`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2b2de",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MBIACgdnA55X"
   },
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs, learning_rate):\n",
    "  with tf.GradientTape() as t:\n",
    "    current_loss = loss(model(inputs), outputs)\n",
    "  dw, db = t.gradient(current_loss, [model.w, model.b])\n",
    "  model.w.assign_sub(learning_rate * dw)\n",
    "  model.b.assign_sub(learning_rate * db)\n",
    "\n",
    "  return current_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587cd5d5",
   "metadata": {
    "colab_type": "text",
    "id": "RwWPaJryD2aN"
   },
   "source": [
    "Теперь будем в цикле обновлять веса и смещения при помощи обучающих данных и смотреть, как эволюционируют `w` и `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c34a99",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdfkR223D9dW"
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "# Запоминаем историю значений 'w' и 'b' для визуализации\n",
    "list_w, list_b = [], []\n",
    "epochs = range(15)\n",
    "losses = []\n",
    "for epoch in epochs:\n",
    "  list_w.append(model.w.numpy())\n",
    "  list_b.append(model.b.numpy())\n",
    "  current_loss = train(model, xs, ys, learning_rate=0.1)\n",
    "  losses.append(current_loss)\n",
    "  print('Эпоха %2d: w=%1.2f b=%1.2f, потери=%2.5f' %\n",
    "        (epoch, list_w[-1], list_b[-1], current_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb13be5c",
   "metadata": {
    "colab_type": "text",
    "id": "EI_1PwOBR6TW"
   },
   "source": [
    "Отобразим прогресс обучаемых переменных в зависимости от эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df31ce",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q8gJThOCNXAp"
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, list_w, 'r', epochs, list_b, 'b')\n",
    "plt.plot([TRUE_w] * len(epochs), 'r--', [TRUE_b] * len(epochs), 'b--')\n",
    "plt.legend(['w', 'b', 'Истинное w', 'Истинное b'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ffabbd",
   "metadata": {
    "colab_type": "text",
    "id": "QsTbG9J2MM9W"
   },
   "source": [
    "## Графики для оценки обучения\n",
    "\n",
    "Теперь отобразим фактические результаты красным цветом, а прогнозы модели — синим на случайном наборе  тестовых точек.\n",
    "\n",
    "Модель довольно точно делает прогнозы на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce91b0a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRHpHCJ3273d"
   },
   "outputs": [],
   "source": [
    "test_inputs  = tf.random.normal(shape=[NUM_EXAMPLES])\n",
    "test_outputs = test_inputs * TRUE_w + TRUE_b\n",
    "\n",
    "predicted_test_outputs = model(test_inputs)\n",
    "plot_data(test_inputs, test_outputs, predicted_test_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35111b0f",
   "metadata": {
    "colab_type": "text",
    "id": "zY-j2FJYSfis"
   },
   "source": [
    "Визуализируем функцию потерь в зависимости от значений каждого из обучаемых весов, к которым модель приблизилась с течением времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded9fa72",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hY-gQWFfOIu-"
   },
   "outputs": [],
   "source": [
    "def plot_loss_for_weights(weights_list, losses):\n",
    "  for idx, weights in enumerate(weights_list):\n",
    "    plt.subplot(120 + idx + 1)\n",
    "    plt.plot(weights['values'], losses, 'r')\n",
    "    plt.plot(weights['values'], losses, 'bo')\n",
    "    plt.xlabel(weights['name'])\n",
    "    if idx==0:\n",
    "        plt.ylabel('Ошибка')\n",
    "    \n",
    "    \n",
    "weights_list = [{ 'name' : \"w\",\n",
    "                  'values' : list_w\n",
    "                },\n",
    "                {\n",
    "                  'name' : \"b\",\n",
    "                  'values' : list_b\n",
    "                }]\n",
    "\n",
    "plot_loss_for_weights(weights_list, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec6017",
   "metadata": {
    "id": "NvrOTmXEBUVS"
   },
   "source": [
    "#### Задание (10 баллов)\n",
    "\n",
    "Для закрепленного за Вами варианта лабораторной работы:\n",
    "   \n",
    "1. Постройте тензор ранга 1 (вектор) со значениями заданной в индивидуальном задании функции одной переменной на заданном в индивидуальном задании отрезке и определите максимальное и минимальное значения функции.\n",
    "\n",
    "2. Постройте график функции с прямыми, соответствующими максимальному и минимальному значениям, подписывая оси и рисунок и создавая легенду.\n",
    "\n",
    "3. Найдите значения производной от функции порядка, указанного в индивидуальном задании, и постройте график полученной функции, подписывая оси и рисунок.\n",
    "\n",
    "4. Постройте тензор ранга 2 (матрицу) со значениями заданной в индивидуальном задании функции двух переменных на заданном в индивидуальном задании прямоугольнике и определите максимальное и минимальное значения функции.\n",
    "\n",
    "5. Постройте 3d график поверхности функции двух переменных, подписывая оси и рисунок.\n",
    "\n",
    "6. Найдите значения смешанной производной от функции порядка, указанного в индивидуальном задании, и постройте 3d график поверхности полученной функции, подписывая оси и рисунок.\n",
    "\n",
    "7. Решите задачу парной линейной регрессии при помощи модели TensorFlow, рассматривая тензор ранга 1 из пункта 1 задания как значения зависимой переменной (отклика), а точки отрезка из индивидуального задания как значения независимой переменной (предиктора). Оцените качество полученной модели по показателю качества регрессии, указанному в индивидуальном задании. Количество эпох, скорость обучения и начальные значения весов выберите самостоятельно, обеспечивая сходимость итерационной процедуры.\n",
    "\n",
    "8. Постройте кривую обучения для показателя качества регрессии, указанного в индивидуальном задании, с зависимостью от количества эпох. Показатель качества регрессия реализуйте как функцию с использованием функций модуля `tf.math`. \n",
    "\n",
    "9. Изобразите на графике точки набора данных (независимой и зависимой переменных) и линию построенной парной регрессии, подписывая оси и рисунок и создавая легенду."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baacb58",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
